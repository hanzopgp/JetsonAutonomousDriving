first test of one for all : ciphar
test for bounding box : caltech101

maybe delete some of the dataset ?
try less data augmentation and add it one by one ?
test f1 score to see if some classes are not working ?

no data augmentation --> too much overfit
no dropout --> too much overfit

test data augmentation:
color jitter : OK
gaussian blur : BOF
dropout 0.6 : OK
rotation : BOF
distorsion : OK
dropout 0.7 : OK

need to check which image of the validation set is not working :
=> seems like there is no class which is worse classified than another
=> after watching the prediction the problem seems to be the distance indeed the classifier works really well when i'm close to the webcam, but when i'm far away it doesnt work anymore

try to unfreeze last CNN layers ?
try to add none class + softmax ?

===================================================================================================================

results not good enough, going for bounding box + only classif

First only classif : took new images easier to classify (close to webcam)
=> got instant huge results and big accuracy (0.96%)
=> need to take some more data to get best performance

Now we have to train a bouding box model which will crop the image and send it to the only classif model
=> gotta take some data thanks to a script + format it with csv file
=> use vgg again but with a different network which does 4 regression thansk to MSE+sigmoid

thinking about downscaling images and going for 100x100 instead of 224x224 for the classification model
indeed the bouding box model will give us small images and we want to avoid upscaling those
we will see if we lose valid_accuracy when using 100x100 images

224*224 96%
128*128 90%
100x100 91%
64*64   67%

idea : combine one for all model + the boudingbox-classification model for inference

what range to chose for bounding box model ? 50x50 to 400x400 images ?
bouding box model working 
starting with 128 neurons first layer
==> first try : Best val loss: 0.000147
getting more data
==> Best val loss: 0.002289, bit worst because i've added some unknown data in validation set
testing with dropout and more patience in early stopping
==> Best val loss: 

trying with some more complex network:
256 neurons first layer :
==> Best val loss: 0.000497
512 neurons first layer :
==> Best val loss: 0.000805

gotta try 256 with dropout maybe and more optimization but before lets take some more data
==> Best val loss: 0.000510

after checking results the only errors the model is making is when the hand is far away
I will add lot of data only containing small bbox and check new results
==> Best val loss: 0.000510

adding data from far + adding validation set really different from training set
now that everything is working lets go back to the beginning
try to full overfit with a big model size, no dropout, no data augmentation
==> Best val loss : 0.000069
we got better performance thanks to the 700 image with only little bbox i've taken

Lets try with some data augmentation:
==> Best val loss : 0.000215
Bad idea we desactivate it

I want to try and even more complex model since it doesn't seem to overfit yet compared to training set (4096)
==> Best val loss : 0.000101

trying with lower learning rate 5e-5 (against 3e-4 previously)
==> Best val loss : 0.000063

trying with lower learning rate 1e-5 (against 5e-5 previously)
==> Best val loss : 0.000092

adding more patience for early stopping (50 against 15 previously)
==> Best val loss : 0.000026

20 patience, 5e-6 lr + new data
==> Best val loss: 0.000032

trying to add data augmentation with albumentation
==> Best val loss : ???






8192 neurons (RAM go BOOM)
==> Best val loss : 

now we try to regularize using dropout, less complex model, data augmentation, and adding even more data as usual
==> Best val loss :



maybe test lr_scheduler.StepLR pytorch ?
try decay at the end ? try MAE ? try data augmentation 




- Intro :
- on veut controler le robot grace a des mouvements de mains 

- partie 1 : 
- comment proceder : 1 reseau one for all, 2 reseau bbox+classif, un model d'object detection ?
- script pour controler le robot, connexion en ssh etc...
- script utilisant les modeles et liant les modeles aux actuateurs

- partie 2 :
- on benchmark des modeles sur computer / jetson
- on test le transfer learning et les modeles custom etc
- format onnx pour accelere l'inference

- partie 3 :
- on a besoin de données pour notre problemes
- les données sont compliqué a trouver
- scripts pour data acquisition
- construction de 3 datasets different pour tester les differents modeles choisit

- partie 4 : 
- choix des modeles performants rentrant dans le benchmark
- quel modele pour quel fonction
- regularisation : data augmentation, dropout, complexite du model, ajout de data
- attention a l'inference : bien choisir validset testset et faire des test en situation reel (webcam)
- choix des hyper parametres











problems :

- what kind of gesture could be nice for our problem (signs must be very different for easier learning)
- what kind of background / distance etc... to have a nice train set in order to generalize
- what to use to train multiple model at a time so we don't waste time ?
- augmentation on train + valid ? augmentation only on train? what kind of augmentation is useful (e.g. color make it generalize but maybe you want to keep the color of the hand ?) ? valid set with backgrounds of photos never seen in train

- what layer to freeze ? (last layers of classifier / all classifier / all classifier + last layers of features)
- how many neurons on classifier layers ?
- what model to chose for transfer learning ?

- what to do in inference when there is no hand movement ? NONE class ? sigmoid output activation ?
- poor performance in inference comparing to validation set

