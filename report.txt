first test of one for all : ciphar
test for bounding box : caltech101

maybe delete some of the dataset ?
try less data augmentation and add it one by one ?
test f1 score to see if some classes are not working ?

no data augmentation --> too much overfit
no dropout --> too much overfit

test data augmentation:
color jitter : OK
gaussian blur : BOF
dropout 0.6 : OK
rotation : BOF
distorsion : OK
dropout 0.7 : OK

need to check which image of the validation set is not working :
=> seems like there is no class which is worse classified than another
=> after watching the prediction the problem seems to be the distance indeed the classifier works really well when i'm close to the webcam, but when i'm far away it doesnt work anymore

try to unfreeze last CNN layers ?
try to add none class + softmax ?

===================================================================================================================

results not good enough, going for bounding box + only classif

First only classif : took new images easier to classify (close to webcam)
=> got instant huge results and big accuracy (0.96%)
=> need to take some more data to get best performance

Now we have to train a bouding box model which will crop the image and send it to the only classif model
=> gotta take some data thanks to a script + format it with csv file
=> use vgg again but with a different network which does 4 regression thansk to MSE+sigmoid

thinking about downscaling images and going for 100x100 instead of 224x224 for the classification model
indeed the bouding box model will give us small images and we want to avoid upscaling those
we will see if we lose valid_accuracy when using 100x100 images

224*224 96%
128*128 90%
100x100 91%
64*64   67%

idea : combine one for all model + the boudingbox-classification model for inference

what range to chose for bounding box model ? 50x50 to 400x400 images ?
bouding box model working 
starting with 128 neurons first layer
==> first try : Best val loss: 0.000147
getting more data
==> Best val loss: 0.002289, bit worst because i've added some unknown data in validation set
testing with dropout and more patience in early stopping
==> Best val loss: 

trying with some more complex network:
256 neurons first layer :
==> Best val loss: 0.000497
512 neurons first layer :
==> Best val loss: 0.000805

gotta try 256 with dropout maybe and more optimization but before lets take some more data
==> Best val loss: 0.000510

after checking results the only errors the model is making is when the hand is far away
I will add lot of data only containing small bbox and check new results
==> Best val loss: 0.000510

adding data from far + adding validation set really different from training set
now that everything is working lets go back to the beginning
try to full overfit with a big model size, no dropout, no data augmentation
==> Best val loss : 0.000069
we got better performance thanks to the 700 image with only little bbox i've taken

Lets try with some data augmentation:
==> Best val loss : 0.000215
Bad idea we desactivate it

I want to try and even more complex model since it doesn't seem to overfit yet compared to training set (4096)
==> Best val loss : 

now we try to regularize using dropout, less complex model, data augmentation, and adding even more data as usual
==> Best val loss :




try decay at the end ? try MAE ? try data augmentation 