{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f76b207a-be69-4b92-ac8a-e0b5e8d0c3f4",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5474f8b-36df-4041-90ca-b32059d1d7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405da49d-205e-48df-89ac-cef5004ef95b",
   "metadata": {},
   "source": [
    "# Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7195184-6670-4816-a211-b78207173be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = False\n",
    "load_ = True\n",
    "\n",
    "label_name = [\"palm_horizontal\", \"L\", \"fist_horizontal\", \"fist_vertical\", \"thumb_up\", \"index\", \"ok\", \"palm_vertical\", \"C\", \"thumb_down\"]\n",
    "test_size = 0.25\n",
    "img_width = 120\n",
    "img_height = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c646f812-716e-4399-ad8e-a8ee630607bc",
   "metadata": {},
   "source": [
    "# Loading and pre processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e8a04b6-d9f8-4b3a-802b-19f3fad2fe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(width, height, oper_sys):\n",
    "    X = []\n",
    "    y = []\n",
    "    stop = False\n",
    "    if oper_sys == \"windows\":\n",
    "        split_ = \"\\\\\"\n",
    "    else:\n",
    "        split_ = \"/\"\n",
    "    for root, dirs, files in tqdm(os.walk(\".\", topdown=False)): \n",
    "        for name in files:\n",
    "            path = os.path.join(root, name)\n",
    "            if path.endswith(\"png\"):\n",
    "                # Loading labels\n",
    "                category = path.split(split_)[4]\n",
    "                label = int(category.split(\"_\")[0]) - 1\n",
    "                y.append(label)\n",
    "                # Loading images\n",
    "                img = cv2.imread(path)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                img = cv2.resize(img, (width, height))\n",
    "                X.append(img)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X.reshape(X.shape[0], height, width, 1), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df934d42-b7de-416b-8cda-31b90cc6b3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 1660.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 120, 120, 1)\n",
      "(0,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/hanzopgp/project/JetsonAutonomousDriving/src/main/hand_gesture_model/hand_gesture_model.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/hanzopgp/project/JetsonAutonomousDriving/src/main/hand_gesture_model/hand_gesture_model.ipynb#ch0000006vscode-remote?line=5'>6</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m\"\u001b[39m\u001b[39mHistogram with \u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m\u001b[39m bins\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/hanzopgp/project/JetsonAutonomousDriving/src/main/hand_gesture_model/hand_gesture_model.ipynb#ch0000006vscode-remote?line=6'>7</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/hanzopgp/project/JetsonAutonomousDriving/src/main/hand_gesture_model/hand_gesture_model.ipynb#ch0000006vscode-remote?line=7'>8</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39;49mtest_size, random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2420\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   <a href='file:///home/hanzopgp/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2416'>2417</a>\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39marrays)\n\u001b[1;32m   <a href='file:///home/hanzopgp/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2418'>2419</a>\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[0;32m-> <a href='file:///home/hanzopgp/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2419'>2420</a>\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   <a href='file:///home/hanzopgp/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2420'>2421</a>\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39;49m\u001b[39m0.25\u001b[39;49m\n\u001b[1;32m   <a href='file:///home/hanzopgp/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2421'>2422</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///home/hanzopgp/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2423'>2424</a>\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/hanzopgp/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2424'>2425</a>\u001b[0m     \u001b[39mif\u001b[39;00m stratify \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2098\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   <a href='file:///home/hanzopgp/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2094'>2095</a>\u001b[0m n_train, n_test \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(n_train), \u001b[39mint\u001b[39m(n_test)\n\u001b[1;32m   <a href='file:///home/hanzopgp/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2096'>2097</a>\u001b[0m \u001b[39mif\u001b[39;00m n_train \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> <a href='file:///home/hanzopgp/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2097'>2098</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   <a href='file:///home/hanzopgp/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2098'>2099</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWith n_samples=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, test_size=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m and train_size=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///home/hanzopgp/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2099'>2100</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///home/hanzopgp/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2100'>2101</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maforementioned parameters.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   <a href='file:///home/hanzopgp/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2101'>2102</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///home/hanzopgp/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2103'>2104</a>\u001b[0m \u001b[39mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "if load_ : \n",
    "    X, y = load_data(width=img_width, height=img_height, oper_sys=\"windows\")\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    plt.hist(y, bins=10, width=0.7)\n",
    "    plt.title(\"Histogram with 'auto' bins\")\n",
    "    plt.show()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334005e0-7b2a-45f4-8087-2ee55d1ffabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomment to check if the images are correctly labeled\n",
    "# for i in range(X.shape[0]):\n",
    "#     if i % 500 == 0:\n",
    "#         plt.imshow(X[i])\n",
    "#         plt.show()\n",
    "#         print(label_name[y[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42a85c8-77d4-4b4f-a1a9-4d734fb00bae",
   "metadata": {},
   "source": [
    "# Building and training simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e77bea-9fcb-4207-b8b4-290c12c26da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(32, (5, 5), activation='relu', input_shape=(img_width, img_height, 1))) \n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu')) \n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(len(label_name), activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5aa5aa-daf0-4d8d-982f-9d14f77b2601",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_ :\n",
    "    model = build_model()\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=5, batch_size=64, verbose=2, validation_data=(X_test, y_test))\n",
    "    model.save('tmp_model.h5')\n",
    "else:\n",
    "    model = tf.keras.models.load_model(\"model.h5\", custom_objects=None, compile=True, options=None)\n",
    "\n",
    "model.summary()\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy: {:2.2f}%'.format(test_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b11ae4-9c06-419e-9ff1-fd6074433d40",
   "metadata": {},
   "source": [
    "# Using model in inference with computer webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f120e45-4555-4ac5-a754-25bcec004896",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e507f5-20ab-4b98-b73e-2ee8226ce45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_ = True\n",
    "\n",
    "if inference_ :\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    before = time.time()\n",
    "    vid = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        ret, frame = vid.read()\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # after = int(time.time() - before)\n",
    "        # if after % 5 == 0:\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.resize(img, (img_width, img_height))\n",
    "        img = img.reshape(1, img_width, img_height, 1)\n",
    "        print(label_name[np.argmax(model.predict(img))])\n",
    "\n",
    "    vid.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2492587-39d8-44e5-ab31-777df417d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For our problem we should take the best prediction out of 100 images, for each final prediction (less error and less decision taken so the robot doesnt go left right left right etc..)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
