{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importation","metadata":{"execution":{"iopub.status.busy":"2022-04-11T16:15:07.160836Z","iopub.execute_input":"2022-04-11T16:15:07.161381Z","iopub.status.idle":"2022-04-11T16:15:08.995876Z","shell.execute_reply.started":"2022-04-11T16:15:07.161292Z","shell.execute_reply":"2022-04-11T16:15:08.995057Z"}}},{"cell_type":"code","source":"import os\nimport copy\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom time import time\nfrom sklearn import preprocessing\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import f1_score \nfrom matplotlib import pyplot as plt\n\nimport torchvision\nfrom torchvision import models, transforms\nfrom torchvision.io import read_image\n\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torch.utils.data import Dataset\n\nfrom pytorch_lightning import LightningModule, Trainer\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2022-04-17T11:41:39.241528Z","iopub.execute_input":"2022-04-17T11:41:39.241829Z","iopub.status.idle":"2022-04-17T11:41:47.085568Z","shell.execute_reply.started":"2022-04-17T11:41:39.241798Z","shell.execute_reply":"2022-04-17T11:41:47.084803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Global variables ","metadata":{}},{"cell_type":"code","source":"INPUT_SIZE = 224\nBATCH_SIZE = 256\nN_CLASS = 5\n\nPATH_LABELS = \"../input/boudingboxonlyhanddataset/index_label.csv\"\nPATH_IMG = \"../input/boudingboxonlyhanddataset/output/output\"\n\nPATH_LABELS_VALID = \"../input/boudingboxonlyhanddataset/index_label_validation.csv\"\nPATH_IMG_VALID = \"../input/boudingboxonlyhanddataset/output_validation/output_validation\"","metadata":{"execution":{"iopub.status.busy":"2022-04-17T11:41:47.087259Z","iopub.execute_input":"2022-04-17T11:41:47.087539Z","iopub.status.idle":"2022-04-17T11:41:47.092630Z","shell.execute_reply.started":"2022-04-17T11:41:47.087504Z","shell.execute_reply":"2022-04-17T11:41:47.091956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data functions","metadata":{"execution":{"iopub.status.busy":"2022-04-11T16:20:53.56609Z","iopub.execute_input":"2022-04-11T16:20:53.566375Z","iopub.status.idle":"2022-04-11T16:20:53.569977Z","shell.execute_reply.started":"2022-04-11T16:20:53.566327Z","shell.execute_reply":"2022-04-11T16:20:53.569332Z"}}},{"cell_type":"code","source":"class HandGestureDataset(Dataset):\n    def __init__(self, annotations_file, img_dir, transform=None):\n        self.img_labels = pd.read_csv(annotations_file)\n        self.img_dir = img_dir\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, os.listdir(self.img_dir)[idx])\n        image = read_image(img_path)\n        label = self.img_labels.loc[self.img_labels[\"index\"] == str(\"output/\"+os.listdir(self.img_dir)[idx])][\"label\"].item()\n        print(label)\n        if self.transform:\n            image = self.transform(image)\n#         image = F.normalize(image, dim = 0)\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2022-04-17T11:41:47.093816Z","iopub.execute_input":"2022-04-17T11:41:47.094440Z","iopub.status.idle":"2022-04-17T11:41:47.104031Z","shell.execute_reply.started":"2022-04-17T11:41:47.094401Z","shell.execute_reply":"2022-04-17T11:41:47.103318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_data_vgg(data_type):\n    ## Parameters fitting vgg/imagenet\n    mean=[0.485, 0.456, 0.406]\n    std=[0.229, 0.224, 0.225]\n\n    ## pytorch transformer objects\n    transformVGGTrain=transforms.Compose([\n            transforms.ToPILImage(),\n        \n#             transforms.ColorJitter(brightness=0.3, hue=0.3),\n#             transforms.RandomPerspective(distortion_scale=0.4, p=0.2),\n#             transforms.RandomAffine(degrees=(0, 5), translate=(0, 0.18), scale=(0.7, 1)),\n#             transforms.RandomSolarize(threshold=192.0),\n#             transforms.RandomAdjustSharpness(sharpness_factor=3),\n#             transforms.RandomAutocontrast(),\n#             transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.01, 1.5)),\n#             transforms.RandomRotation(degrees=(-15, 15)),\n        \n            ## too much\n#             transforms.RandomPosterize(bits=2),\n#             transforms.RandomInvert(),\n#             transforms.RandomEqualize(),\n        \n            transforms.Resize(size=(INPUT_SIZE, INPUT_SIZE)),\n            transforms.ToTensor(),\n#             transforms.Normalize(mean, std) ## test with and without\n        ])\n    transformVGGValid=transforms.Compose([\n            transforms.ToPILImage(),\n            transforms.Resize(size=(INPUT_SIZE, INPUT_SIZE)),\n            transforms.ToTensor(),\n#             transforms.Normalize(mean, std) ## test with and without\n        ])\n\n    if data_type == \"custom\":\n        ## Custom dataset\n        VGG_dataset_train = HandGestureDataset(PATH_LABELS, PATH_IMG, transformVGGTrain)\n        VGG_dataset_valid = HandGestureDataset(PATH_LABELS_VALID, PATH_IMG_VALID, transformVGGValid)\n        VGG_trainloader = torch.utils.data.DataLoader(VGG_dataset_train, batch_size=BATCH_SIZE, pin_memory=True, shuffle=True)\n        VGG_validloader = torch.utils.data.DataLoader(VGG_dataset_valid, batch_size=BATCH_SIZE, pin_memory=True, shuffle=True)\n    \n    return VGG_trainloader, VGG_validloader","metadata":{"execution":{"iopub.status.busy":"2022-04-17T11:41:47.107898Z","iopub.execute_input":"2022-04-17T11:41:47.108572Z","iopub.status.idle":"2022-04-17T11:41:47.123156Z","shell.execute_reply.started":"2022-04-17T11:41:47.108534Z","shell.execute_reply":"2022-04-17T11:41:47.122447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading data into pytorch dataset and dataloader objects","metadata":{"execution":{"iopub.status.busy":"2022-02-15T15:49:41.69497Z","iopub.execute_input":"2022-02-15T15:49:41.695334Z","iopub.status.idle":"2022-02-15T15:49:46.639507Z","shell.execute_reply.started":"2022-02-15T15:49:41.695293Z","shell.execute_reply":"2022-02-15T15:49:46.638679Z"}}},{"cell_type":"code","source":"VGG_trainloader, VGG_validloader = prepare_data_vgg(\"custom\")","metadata":{"execution":{"iopub.status.busy":"2022-04-17T11:41:47.124524Z","iopub.execute_input":"2022-04-17T11:41:47.124812Z","iopub.status.idle":"2022-04-17T11:41:47.154322Z","shell.execute_reply.started":"2022-04-17T11:41:47.124777Z","shell.execute_reply":"2022-04-17T11:41:47.153688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for img in next(iter(VGG_trainloader)):\n#     for i in img[:20]:\n#         i = i.permute(1,2,0)\n#         plt.imshow(np.array(i))\n#         plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T11:41:47.156973Z","iopub.execute_input":"2022-04-17T11:41:47.157171Z","iopub.status.idle":"2022-04-17T11:41:47.162871Z","shell.execute_reply.started":"2022-04-17T11:41:47.157146Z","shell.execute_reply":"2022-04-17T11:41:47.162090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model functions","metadata":{}},{"cell_type":"code","source":"def train(model, epochs, train_loader, valid_loader, learning_rate, patience, feature_extract=False):\n    ## Early stopping variables\n    es = EarlyStopping(patience=patience)\n    terminate_training = False\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_loss = 0.0\n     \n    ## TensorBoard setup\n    model = model.to(device)\n    writer = SummaryWriter(f\"{TB_PATH}/{model.name}\")\n    \n    ## Training only the parameters where we require gradient since we are fine-tuning\n    params_to_update = model.parameters()\n    print(\"params to learn:\")\n    if feature_extract:\n        params_to_update = []\n        for name,param in model.named_parameters():\n            if param.requires_grad == True:\n                params_to_update.append(param)\n                print(\"\\t\", name)\n    else:\n        for name,param in model.named_parameters():\n            if param.requires_grad == True:\n                print(\"\\t\", name)\n                \n    ## Setting up our optimizer\n    optim = torch.optim.Adam(params_to_update, lr=learning_rate)\n    \n    ## Setting up our loss function\n    loss = nn.CrossEntropyLoss()\n    \n    ## Running the train loop\n    print(f\"running {model.name}\")\n    for epoch in range(epochs):\n        cumloss, , count = 0, 0\n        model.train()\n        for x,y in train_loader:\n            optim.zero_grad()\n            x = x.to(device)\n            y = torch.as_tensor(y)\n            y = y.to(device)\n            yhat = model(x)\n            l = loss(yhat, y)\n            l.backward()\n            optim.step()\n            cumloss += l * len(x)\n            count += len(x)\n        print(\"epoch :\", epoch, end=\"\")\n        print(\", train_loss: \", cumloss.cpu().item()/count, end=\"\")\n        if epoch % 1 == 0:\n            model.eval()\n            with torch.no_grad():\n                valid_cumloss, count = 0, 0\n                for x,y in valid_loader:\n                    x = x.to(device)\n                    y = torch.as_tensor(y)\n                    y = y.to(device)\n                    yhat = model(x)\n                    valid_cumloss += loss(yhat,y) * len(x)\n                    count += len(x)\n                print(\", valid_loss: \", valid_cumloss.cpu().item()/count, end=\"\")\n                ## Early stopping\n                if valid_cumloss/count > best_loss:\n                    best_loss = valid_cumloss/count\n                    best_model_wts = copy.deepcopy(model.state_dict())\n                if es.step(valid_cumloss.cpu().item()/count):\n                    terminate_training = True\n                    break\n        if terminate_training:\n            break\n    print('Best val loss: {:4f}'.format(best_loss))\n    ## Returns the best model\n    model.load_state_dict(best_model_wts)\n    return model\n\ndef set_parameter_requires_grad(model, feature_extract):\n    if feature_extract:\n        for name,p in model.named_parameters():\n            if \"features\" in name:\n                p.requires_grad = False    \n            else:\n                p.requires_grad = True  ","metadata":{"execution":{"iopub.status.busy":"2022-04-17T11:41:47.166026Z","iopub.execute_input":"2022-04-17T11:41:47.166223Z","iopub.status.idle":"2022-04-17T11:41:47.189418Z","shell.execute_reply.started":"2022-04-17T11:41:47.166199Z","shell.execute_reply":"2022-04-17T11:41:47.188643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the model and modifying the classifier part\n### Maybe we could try to modify only the last classifier layer ?","metadata":{"execution":{"iopub.status.busy":"2022-04-11T16:22:20.614632Z","iopub.execute_input":"2022-04-11T16:22:20.614896Z","iopub.status.idle":"2022-04-11T16:22:20.618197Z","shell.execute_reply.started":"2022-04-11T16:22:20.614868Z","shell.execute_reply":"2022-04-11T16:22:20.617386Z"}}},{"cell_type":"code","source":"TB_PATH = \"/tmp/logs/sceance2\"\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n## Loading vgg16 model pretrained on imagenet\nvgg = models.vgg16(pretrained=True)\n\nvgg.classifier = nn.Sequential(nn.Linear(25088, 100), \n                               nn.ReLU(), \n                               nn.Dropout(0.5),        \n                               nn.Linear(100, N_CLASS), \n                               nn.Softmax(dim=1))\n\nprint(vgg.eval())\n\n## Sets all the requires grad of the classifier layers to True\nset_parameter_requires_grad(vgg, True)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T11:41:47.190722Z","iopub.execute_input":"2022-04-17T11:41:47.191054Z","iopub.status.idle":"2022-04-17T11:42:12.056975Z","shell.execute_reply.started":"2022-04-17T11:41:47.191017Z","shell.execute_reply":"2022-04-17T11:42:12.056219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Implementing early stopping","metadata":{}},{"cell_type":"code","source":"class EarlyStopping(object):\n    def __init__(self, mode='min', min_delta=0, patience=10, percentage=False):\n        self.mode = mode\n        self.min_delta = min_delta\n        self.patience = patience\n        self.best = None\n        self.num_bad_epochs = 0\n        self.is_better = None\n        self._init_is_better(mode, min_delta, percentage)\n        if patience == 0:\n            self.is_better = lambda a, b: True\n            self.step = lambda a: False\n\n    def step(self, metrics):\n        if self.best is None:\n            self.best = metrics\n            return False\n        if np.isnan(metrics):\n            return True\n        if self.is_better(metrics, self.best):\n            self.num_bad_epochs = 0\n            self.best = metrics\n        else:\n            self.num_bad_epochs += 1\n        if self.num_bad_epochs >= self.patience:\n            return True\n        return False\n\n    def _init_is_better(self, mode, min_delta, percentage):\n        if mode not in {'min', 'max'}:\n            raise ValueError('mode ' + mode + ' is unknown!')\n        if not percentage:\n            if mode == 'min':\n                self.is_better = lambda a, best: a < best - min_delta\n            if mode == 'max':\n                self.is_better = lambda a, best: a > best + min_delta\n        else:\n            if mode == 'min':\n                self.is_better = lambda a, best: a < best - (\n                            best * min_delta / 100)\n            if mode == 'max':\n                self.is_better = lambda a, best: a > best + (\n                            best * min_delta / 100)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T11:42:12.058170Z","iopub.execute_input":"2022-04-17T11:42:12.059903Z","iopub.status.idle":"2022-04-17T11:42:12.071010Z","shell.execute_reply.started":"2022-04-17T11:42:12.059862Z","shell.execute_reply":"2022-04-17T11:42:12.070365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training only the modified parts of the classifier","metadata":{}},{"cell_type":"code","source":"## Fine-tuning the model on our data\nvgg.name = \"VGG\"\n\nbest_model = train(model=vgg, \n                   epochs=500, \n                   train_loader=VGG_trainloader, \n                   valid_loader=VGG_validloader, \n                   learning_rate=3e-4, ## learning rate for Adam optimizer\n                   patience=5) ## metric for earlystopping : val_loss ","metadata":{"execution":{"iopub.status.busy":"2022-04-17T11:42:12.073709Z","iopub.execute_input":"2022-04-17T11:42:12.074024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking predictions","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    for x,y in VGG_validloader:\n        x = x.to(device)\n        y = le.fit_transform(y)\n        y = torch.as_tensor(y)\n        y = y.to(device)\n        yhat = best_model(x)\n        for i in range(50):\n            ## need function to show bouding box\n#             plt.imshow(x.cpu()[i].permute(1,2,0))\n#             str_ = LABELS[yhat.cpu()[i].argmax().item()]\n#             plt.title(\"Pred:\" + str_)\n#             plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving the model in .pth and .onnx extension","metadata":{}},{"cell_type":"code","source":"PATH = \"./\"\ntorch.save(best_model.state_dict(), os.path.join(PATH,\"boundingbox_vgg.pth\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del vgg\ndel best_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = models.vgg16(pretrained=True)\n# model.classifier[0] = nn.Linear(25088, 8192)\n# model.classifier[3] = nn.Linear(8192, 1024)\n# model.classifier[6] = nn.Linear(1024, N_CLASS)\n# model.load_state_dict(torch.load(os.path.join(PATH,\"vgg.pth\"), map_location='cpu'))\n# model.eval() \n\n# dummy_input = torch.randn(BATCH_SIZE, 3, INPUT_SIZE, INPUT_SIZE)  \n# torch.onnx.export(model,   \n#                   dummy_input, \n#                   \"vgg.onnx\",\n#                   export_params=True,\n#                   do_constant_folding=True, \n#                   input_names = ['modelInput'],\n#                   output_names = ['modelOutput'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}