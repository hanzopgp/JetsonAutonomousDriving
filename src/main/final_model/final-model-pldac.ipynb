{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importation","metadata":{"execution":{"iopub.status.busy":"2022-04-11T16:15:07.160836Z","iopub.execute_input":"2022-04-11T16:15:07.161381Z","iopub.status.idle":"2022-04-11T16:15:08.995876Z","shell.execute_reply.started":"2022-04-11T16:15:07.161292Z","shell.execute_reply":"2022-04-11T16:15:08.995057Z"}}},{"cell_type":"code","source":"import os\nimport copy\nimport numpy as np\nfrom tqdm import tqdm\nfrom time import time\n\nimport torchvision\nfrom torchvision import models, transforms\n\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torch.utils.data import Dataset\n\nfrom pytorch_lightning import LightningModule, Trainer\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\n\n# !pip install torchvision onnx-coreml","metadata":{"execution":{"iopub.status.busy":"2022-04-11T19:27:05.603603Z","iopub.execute_input":"2022-04-11T19:27:05.604044Z","iopub.status.idle":"2022-04-11T19:27:14.086965Z","shell.execute_reply.started":"2022-04-11T19:27:05.603923Z","shell.execute_reply":"2022-04-11T19:27:14.086076Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Global variables ","metadata":{}},{"cell_type":"code","source":"INPUT_SIZE = 224\nBATCH_SIZE = 128\nN_CLASS = 5\n\nPATH_LABELS = \"\"\nPATH_IMG = \"\"\nPATH_LABELS_VALID = \"\"\nPATH_IMG_VALID = \"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-11T19:27:14.089264Z","iopub.execute_input":"2022-04-11T19:27:14.089528Z","iopub.status.idle":"2022-04-11T19:27:14.096207Z","shell.execute_reply.started":"2022-04-11T19:27:14.089490Z","shell.execute_reply":"2022-04-11T19:27:14.095501Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Data functions","metadata":{"execution":{"iopub.status.busy":"2022-04-11T16:20:53.566090Z","iopub.execute_input":"2022-04-11T16:20:53.566375Z","iopub.status.idle":"2022-04-11T16:20:53.569977Z","shell.execute_reply.started":"2022-04-11T16:20:53.566327Z","shell.execute_reply":"2022-04-11T16:20:53.569332Z"}}},{"cell_type":"code","source":"class HandGestureDataset(Dataset):\n    def __init__(self, annotations_file, img_dir, transform=None):\n        self.img_labels = pd.read_csv(annotations_file)\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n        image = read_image(img_path)\n        label = F.one_hot(self.img_labels.iloc[idx, 1], num_classes=N_CLASS)\n        if self.transform:\n            image = self.transform(image)\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2022-04-11T19:27:14.097311Z","iopub.execute_input":"2022-04-11T19:27:14.097660Z","iopub.status.idle":"2022-04-11T19:27:14.112291Z","shell.execute_reply.started":"2022-04-11T19:27:14.097623Z","shell.execute_reply":"2022-04-11T19:27:14.111548Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def prepare_data_vgg(data_type):\n    ## Parameters fitting vgg/imagenet\n    mean=[0.485, 0.456, 0.406]\n    std=[0.229, 0.224, 0.225]\n\n    ## pytorch transformer objects\n    transformVGGTrain=transforms.Compose([\n            transforms.RandomResizedCrop(INPUT_SIZE),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean, std)\n        ])\n    transformVGGValid=transforms.Compose([\n            transforms.Resize(INPUT_SIZE),\n            transforms.CenterCrop(INPUT_SIZE),\n            transforms.ToTensor(),\n            transforms.Normalize(mean, std)\n        ])\n\n    if data_type == \"custom\":\n        ## Custom dataset\n        VGG_trainset = HandGestureDataset(PATH_LABELS, PATH_IMG, transformVGGTrain)\n        VGG_trainloader = torch.utils.data.DataLoader(VGG_trainset, BATCH_SIZE=BATCH_SIZE, pin_memory=True, shuffle=True)\n        VGG_validset = HandGestureDataset(PATH_LABELS_VALID, PATH_IMG_VALID, transformVGGValid)\n        VGG_validloader = torch.utils.data.DataLoader(VGG_validset, BATCH_SIZE=BATCH_SIZE, pin_memory=True, shuffle=True)\n    \n    ## CIPHAR10\n    if data_type == \"ciphar10\":\n        VGG_trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transformVGGTrain)\n        VGG_trainloader = torch.utils.data.DataLoader(VGG_trainset, batch_size=BATCH_SIZE, pin_memory=True, shuffle=True)\n        VGG_validset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transformVGGValid)\n        VGG_validloader = torch.utils.data.DataLoader(VGG_validset, batch_size=BATCH_SIZE, pin_memory=True, shuffle=True)\n    \n    return VGG_trainloader, VGG_validloader","metadata":{"execution":{"iopub.status.busy":"2022-04-11T19:27:14.115108Z","iopub.execute_input":"2022-04-11T19:27:14.115413Z","iopub.status.idle":"2022-04-11T19:27:14.127105Z","shell.execute_reply.started":"2022-04-11T19:27:14.115351Z","shell.execute_reply":"2022-04-11T19:27:14.125994Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Loading data into pytorch dataset and dataloader objects","metadata":{"execution":{"iopub.status.busy":"2022-02-15T15:49:41.69497Z","iopub.execute_input":"2022-02-15T15:49:41.695334Z","iopub.status.idle":"2022-02-15T15:49:46.639507Z","shell.execute_reply.started":"2022-02-15T15:49:41.695293Z","shell.execute_reply":"2022-02-15T15:49:46.638679Z"}}},{"cell_type":"code","source":"VGG_trainloader, VGG_validloader = prepare_data_vgg(\"ciphar10\")","metadata":{"execution":{"iopub.status.busy":"2022-04-11T19:27:14.129904Z","iopub.execute_input":"2022-04-11T19:27:14.131350Z","iopub.status.idle":"2022-04-11T19:27:21.867169Z","shell.execute_reply.started":"2022-04-11T19:27:14.131309Z","shell.execute_reply":"2022-04-11T19:27:21.866451Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Model functions","metadata":{}},{"cell_type":"code","source":"def accuracy(yhat,y):\n    if len(y.shape) == 1 or y.size(1) == 1:\n        return (torch.argmax(yhat, 1).view(y.size(0), -1) == y.view(-1, 1)).double().mean()\n    return (torch.argmax(yhat, 1). view(-1) == torch.argmax(y, 1).view(-1)).double().mean()\n\ndef train(model, epochs, train_loader, valid_loader, learning_rate, patience, feature_extract=False):\n    ## Early stopping variables\n    es = EarlyStopping(patience=patience)\n    terminate_training = False\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n     \n    ## TensorBoard setup\n    model = model.to(device)\n    writer = SummaryWriter(f\"{TB_PATH}/{model.name}\")\n    \n    ## Training only the parameters where we require gradient since we are fine-tuning\n    params_to_update = model.parameters()\n    print(\"params to learn:\")\n    if feature_extract:\n        params_to_update = []\n        for name,param in model.named_parameters():\n            if param.requires_grad == True:\n                params_to_update.append(param)\n                print(\"\\t\", name)\n    else:\n        for name,param in model.named_parameters():\n            if param.requires_grad == True:\n                print(\"\\t\", name)\n                \n    ## Setting up our optimizer\n    optim = torch.optim.Adam(params_to_update, lr=learning_rate)\n    \n    ## Setting up our loss function\n    loss = nn.CrossEntropyLoss()\n    \n    ## Running the train loop\n    print(f\"running {model.name}\")\n    for epoch in range(epochs):\n        cumloss, cumacc, count = 0, 0, 0\n        model.train()\n        for x,y in train_loader:\n            optim.zero_grad()\n            x,y = x.to(device), y.to(device)\n            yhat = model(x)\n            l = loss(yhat, y)\n            l.backward()\n            optim.step()\n            cumloss += l * len(x)\n            cumacc += accuracy(yhat, y) * len(x)\n            count += len(x)\n#         writer.add_scalar('loss/train', cumloss/count,epoch)\n#         writer.add_scalar('accuracy/train', cumacc/count,epoch)\n        print(\"epoch :\", epoch, end=\"\")\n        print(\", train_loss: \", cumloss.cpu()/count, end=\"\")\n        print(\", train_acc: \", cumacc.cpu()/count, end=\"\")\n        if epoch % 1 == 0:\n            model.eval()\n            with torch.no_grad():\n                valid_cumloss, valid_cumacc, count = 0, 0, 0\n                for x,y in valid_loader:\n                    x,y = x.to(device), y.to(device)\n                    yhat = model(x)\n                    valid_cumloss += loss(yhat,y) * len(x)\n                    valid_cumacc += accuracy(yhat,y) * len(x)\n                    count += len(x)\n#                 writer.add_scalar(f'loss/valid', valid_cumloss/count,epoch)\n#                 writer.add_scalar('accuracy/valid', valid_cumacc/count,epoch)\n                print(\", valid_loss: \", valid_cumloss.cpu()/count, end=\"\")\n                print(\", valid_acc: \", valid_cumacc.cpu()/count)\n                ## Early stopping\n                if valid_cumacc/count > best_acc:\n                    best_acc = valid_cumacc/count\n                    best_model_wts = copy.deepcopy(model.state_dict())\n                if es.step(valid_cumloss.cpu()/count):\n                    terminate_training = True\n                    break\n        if terminate_training:\n            break\n    print('Best val Acc: {:4f}'.format(best_acc))\n    ## Returns the best model\n    model.load_state_dict(best_model_wts)\n    return model\n\ndef set_parameter_requires_grad(model, feature_extract):\n    if feature_extract:\n        for name,p in model.named_parameters():\n            if \"features\" in name:\n                p.requires_grad = False    \n            else:\n                p.requires_grad = True  ","metadata":{"execution":{"iopub.status.busy":"2022-04-11T19:27:21.868580Z","iopub.execute_input":"2022-04-11T19:27:21.868908Z","iopub.status.idle":"2022-04-11T19:27:21.890668Z","shell.execute_reply.started":"2022-04-11T19:27:21.868778Z","shell.execute_reply":"2022-04-11T19:27:21.889827Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Loading the model and modifying the classifier part\n### Maybe we could try to modify only the last classifier layer ?","metadata":{"execution":{"iopub.status.busy":"2022-04-11T16:22:20.614632Z","iopub.execute_input":"2022-04-11T16:22:20.614896Z","iopub.status.idle":"2022-04-11T16:22:20.618197Z","shell.execute_reply.started":"2022-04-11T16:22:20.614868Z","shell.execute_reply":"2022-04-11T16:22:20.617386Z"}}},{"cell_type":"code","source":"TB_PATH = \"/tmp/logs/sceance2\"\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n## Loading vgg16 model pretrained on imagenet\nvgg = models.vgg16(pretrained=True)\n\n## Modifies the vgg network classifier layers to fit our problem\nvgg.classifier[0] = nn.Linear(25088, 8192)\nvgg.classifier[3] = nn.Linear(8192, 1024)\nvgg.classifier[6] = nn.Linear(1024, 10)\nprint(vgg.eval())\n\n## Sets all the requires grad of the classifier layers to True\nset_parameter_requires_grad(vgg, True)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T19:27:21.892908Z","iopub.execute_input":"2022-04-11T19:27:21.893169Z","iopub.status.idle":"2022-04-11T19:27:36.157264Z","shell.execute_reply.started":"2022-04-11T19:27:21.893133Z","shell.execute_reply":"2022-04-11T19:27:36.156553Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Implementing early stopping","metadata":{}},{"cell_type":"code","source":"class EarlyStopping(object):\n    def __init__(self, mode='min', min_delta=0, patience=10, percentage=False):\n        self.mode = mode\n        self.min_delta = min_delta\n        self.patience = patience\n        self.best = None\n        self.num_bad_epochs = 0\n        self.is_better = None\n        self._init_is_better(mode, min_delta, percentage)\n        if patience == 0:\n            self.is_better = lambda a, b: True\n            self.step = lambda a: False\n\n    def step(self, metrics):\n        if self.best is None:\n            self.best = metrics\n            return False\n        if np.isnan(metrics):\n            return True\n        if self.is_better(metrics, self.best):\n            self.num_bad_epochs = 0\n            self.best = metrics\n#             print('improvement!')\n        else:\n            self.num_bad_epochs += 1\n#             print(f'no improvement, bad_epochs counter: {self.num_bad_epochs}')\n        if self.num_bad_epochs >= self.patience:\n            return True\n        return False\n\n    def _init_is_better(self, mode, min_delta, percentage):\n        if mode not in {'min', 'max'}:\n            raise ValueError('mode ' + mode + ' is unknown!')\n        if not percentage:\n            if mode == 'min':\n                self.is_better = lambda a, best: a < best - min_delta\n            if mode == 'max':\n                self.is_better = lambda a, best: a > best + min_delta\n        else:\n            if mode == 'min':\n                self.is_better = lambda a, best: a < best - (\n                            best * min_delta / 100)\n            if mode == 'max':\n                self.is_better = lambda a, best: a > best + (\n                            best * min_delta / 100)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T19:27:36.158573Z","iopub.execute_input":"2022-04-11T19:27:36.158962Z","iopub.status.idle":"2022-04-11T19:27:36.170957Z","shell.execute_reply.started":"2022-04-11T19:27:36.158924Z","shell.execute_reply":"2022-04-11T19:27:36.170102Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Training only the modified parts of the classifier","metadata":{}},{"cell_type":"code","source":"## Fine-tuning the model on our data\nvgg.name = \"VGG\"\nbest_model = train(model=vgg, \n                   epochs=3, \n                   train_loader=VGG_trainloader, \n                   valid_loader=VGG_validloader, \n                   learning_rate=1e-3, ## learning rate for Adam optimizer\n                   patience=5) ## metric for earlystopping : val_loss","metadata":{"execution":{"iopub.status.busy":"2022-04-11T19:27:36.172066Z","iopub.execute_input":"2022-04-11T19:27:36.172299Z","iopub.status.idle":"2022-04-11T19:30:06.961901Z","shell.execute_reply.started":"2022-04-11T19:27:36.172269Z","shell.execute_reply":"2022-04-11T19:30:06.960865Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Checking metrics","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving the model in .pth and .onnx extension","metadata":{}},{"cell_type":"code","source":"PATH = \"./\"\ntorch.save(vgg.state_dict(), os.path.join(PATH,\"vgg.pth\"))\nmodel = models.vgg16(pretrained=True)\nmodel.classifier[0] = nn.Linear(25088, 8192)\nmodel.classifier[3] = nn.Linear(8192, 1024)\nmodel.classifier[6] = nn.Linear(1024, 10)\nmodel.load_state_dict(torch.load(os.path.join(PATH,\"vgg.pth\"), map_location='cpu'))\nmodel.eval() \n\ndummy_input = torch.randn(BATCH_SIZE, 3, INPUT_SIZE, INPUT_SIZE)  \ntorch.onnx.export(model,   \n                  dummy_input, \n                  \"vgg.onnx\",\n                  export_params=True,\n                  do_constant_folding=True, \n                  input_names = ['modelInput'],\n                  output_names = ['modelOutput'])","metadata":{"execution":{"iopub.status.busy":"2022-04-11T19:30:06.963128Z","iopub.status.idle":"2022-04-11T19:30:06.963801Z","shell.execute_reply.started":"2022-04-11T19:30:06.963528Z","shell.execute_reply":"2022-04-11T19:30:06.963556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}