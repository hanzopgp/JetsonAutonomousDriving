{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importation","metadata":{"execution":{"iopub.status.busy":"2022-04-11T16:15:07.160836Z","iopub.execute_input":"2022-04-11T16:15:07.161381Z","iopub.status.idle":"2022-04-11T16:15:08.995876Z","shell.execute_reply.started":"2022-04-11T16:15:07.161292Z","shell.execute_reply":"2022-04-11T16:15:08.995057Z"}}},{"cell_type":"code","source":"import os\nimport copy\nimport numpy as np\nfrom tqdm import tqdm\nfrom time import time\n\nimport torchvision\nfrom torchvision import models, transforms\n\nimport torch\nfrom torch import nn\nfrom torch.utils.tensorboard import SummaryWriter\n\nfrom pytorch_lightning import LightningModule, Trainer\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\n\n# !pip install torchvision onnx-coreml","metadata":{"execution":{"iopub.status.busy":"2022-04-11T18:16:35.913108Z","iopub.execute_input":"2022-04-11T18:16:35.913422Z","iopub.status.idle":"2022-04-11T18:16:44.688576Z","shell.execute_reply.started":"2022-04-11T18:16:35.913343Z","shell.execute_reply":"2022-04-11T18:16:44.687528Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Data functions","metadata":{"execution":{"iopub.status.busy":"2022-04-11T16:20:53.566090Z","iopub.execute_input":"2022-04-11T16:20:53.566375Z","iopub.status.idle":"2022-04-11T16:20:53.569977Z","shell.execute_reply.started":"2022-04-11T16:20:53.566327Z","shell.execute_reply":"2022-04-11T16:20:53.569332Z"}}},{"cell_type":"code","source":"def prepare_data_vgg():\n    ## Parameters fitting vgg/imagenet\n    input_size = 224\n    batch_size = 128\n    mean=[0.485, 0.456, 0.406]\n    std=[0.229, 0.224, 0.225]\n\n    ## pytorch transformer objects\n    transformVGGTrain=transforms.Compose([\n            transforms.RandomResizedCrop(input_size),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean, std)\n        ])\n    transformVGGValid=transforms.Compose([\n            transforms.Resize(input_size),\n            transforms.CenterCrop(input_size),\n            transforms.ToTensor(),\n            transforms.Normalize(mean, std)\n        ])\n\n    VGG_trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transformVGGTrain)\n    VGG_trainloader = torch.utils.data.DataLoader(VGG_trainset, batch_size=batch_size, pin_memory=True, shuffle=True)\n\n    VGG_validset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transformVGGValid)\n    VGG_validloader = torch.utils.data.DataLoader(VGG_validset, batch_size=batch_size, pin_memory=True, shuffle=True)\n    \n    return VGG_trainloader, VGG_validloader","metadata":{"execution":{"iopub.status.busy":"2022-04-11T18:16:44.690765Z","iopub.execute_input":"2022-04-11T18:16:44.691027Z","iopub.status.idle":"2022-04-11T18:16:44.702491Z","shell.execute_reply.started":"2022-04-11T18:16:44.690989Z","shell.execute_reply":"2022-04-11T18:16:44.701827Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Loading data into pytorch dataset and dataloader objects","metadata":{"execution":{"iopub.status.busy":"2022-02-15T15:49:41.69497Z","iopub.execute_input":"2022-02-15T15:49:41.695334Z","iopub.status.idle":"2022-02-15T15:49:46.639507Z","shell.execute_reply.started":"2022-02-15T15:49:41.695293Z","shell.execute_reply":"2022-02-15T15:49:46.638679Z"}}},{"cell_type":"code","source":"VGG_trainloader, VGG_validloader = prepare_data_vgg()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T18:16:44.705496Z","iopub.execute_input":"2022-04-11T18:16:44.706736Z","iopub.status.idle":"2022-04-11T18:16:52.043716Z","shell.execute_reply.started":"2022-04-11T18:16:44.706695Z","shell.execute_reply":"2022-04-11T18:16:52.042967Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Model functions","metadata":{}},{"cell_type":"code","source":"def accuracy(yhat,y):\n    if len(y.shape) == 1 or y.size(1) == 1:\n        return (torch.argmax(yhat, 1).view(y.size(0), -1) == y.view(-1, 1)).double().mean()\n    return (torch.argmax(yhat, 1). view(-1) == torch.argmax(y, 1).view(-1)).double().mean()\n\ndef train(model, epochs, train_loader, valid_loader, learning_rate, patience, feature_extract=False):\n    ## Early stopping variables\n    es = EarlyStopping(patience=patience)\n    terminate_training = False\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n     \n    ## TensorBoard setup\n    model = model.to(device)\n    writer = SummaryWriter(f\"{TB_PATH}/{model.name}\")\n    \n    ## Training only the parameters where we require gradient since we are fine-tuning\n    params_to_update = model.parameters()\n    print(\"params to learn:\")\n    if feature_extract:\n        params_to_update = []\n        for name,param in model.named_parameters():\n            if param.requires_grad == True:\n                params_to_update.append(param)\n                print(\"\\t\", name)\n    else:\n        for name,param in model.named_parameters():\n            if param.requires_grad == True:\n                print(\"\\t\", name)\n                \n    ## Setting up our optimizer\n    optim = torch.optim.Adam(params_to_update, lr=learning_rate)\n    \n    ## Setting up our loss function\n    loss = nn.CrossEntropyLoss()\n    \n    ## Running the train loop\n    print(f\"running {model.name}\")\n    for epoch in range(epochs):\n        cumloss, cumacc, count = 0, 0, 0\n        model.train()\n        for x,y in train_loader:\n            optim.zero_grad()\n            x,y = x.to(device), y.to(device)\n            yhat = model(x)\n            l = loss(yhat, y)\n            l.backward()\n            optim.step()\n            cumloss += l * len(x)\n            cumacc += accuracy(yhat, y) * len(x)\n            count += len(x)\n#         writer.add_scalar('loss/train', cumloss/count,epoch)\n#         writer.add_scalar('accuracy/train', cumacc/count,epoch)\n        print(\"epoch :\", epoch, end=\"\")\n        print(\", train_loss: \", cumloss.cpu()/count, end=\"\")\n        print(\", train_acc: \", cumacc.cpu()/count, end=\"\")\n        if epoch % 1 == 0:\n            model.eval()\n            with torch.no_grad():\n                valid_cumloss, valid_cumacc, count = 0, 0, 0\n                for x,y in valid_loader:\n                    x,y = x.to(device), y.to(device)\n                    yhat = model(x)\n                    valid_cumloss += loss(yhat,y) * len(x)\n                    valid_cumacc += accuracy(yhat,y) * len(x)\n                    count += len(x)\n#                 writer.add_scalar(f'loss/valid', valid_cumloss/count,epoch)\n#                 writer.add_scalar('accuracy/valid', valid_cumacc/count,epoch)\n                print(\", valid_loss: \", valid_cumloss.cpu()/count, end=\"\")\n                print(\", valid_acc: \", valid_cumacc.cpu()/count)\n                ## Early stopping\n                if valid_cumacc/count > best_acc:\n                    best_acc = valid_cumacc/count\n                    best_model_wts = copy.deepcopy(model.state_dict())\n                if es.step(valid_cumloss.cpu()/count):\n                    terminate_training = True\n                    break\n        if terminate_training:\n            break\n    print('Best val Acc: {:4f}'.format(best_acc))\n    ## Returns the best model\n    model.load_state_dict(best_model_wts)\n    return model\n\ndef set_parameter_requires_grad(model, feature_extract):\n    if feature_extract:\n        for name,p in model.named_parameters():\n            if \"features\" in name:\n                p.requires_grad = False    \n            else:\n                p.requires_grad = True  ","metadata":{"execution":{"iopub.status.busy":"2022-04-11T18:16:52.045725Z","iopub.execute_input":"2022-04-11T18:16:52.046157Z","iopub.status.idle":"2022-04-11T18:16:52.066261Z","shell.execute_reply.started":"2022-04-11T18:16:52.046118Z","shell.execute_reply":"2022-04-11T18:16:52.065565Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Loading the model and modifying the classifier part\n### Maybe we could try to modify only the last classifier layer ?","metadata":{"execution":{"iopub.status.busy":"2022-04-11T16:22:20.614632Z","iopub.execute_input":"2022-04-11T16:22:20.614896Z","iopub.status.idle":"2022-04-11T16:22:20.618197Z","shell.execute_reply.started":"2022-04-11T16:22:20.614868Z","shell.execute_reply":"2022-04-11T16:22:20.617386Z"}}},{"cell_type":"code","source":"TB_PATH = \"/tmp/logs/sceance2\"\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n## Loading vgg16 model pretrained on imagenet\nvgg = models.vgg16(pretrained=True)\n\n## Modifies the vgg network classifier layers to fit our problem\nvgg.classifier[0] = nn.Linear(25088, 8192)\nvgg.classifier[3] = nn.Linear(8192, 1024)\nvgg.classifier[6] = nn.Linear(1024, 10)\nprint(vgg.eval())\n\n## Sets all the requires grad of the classifier layers to True\nset_parameter_requires_grad(vgg, True)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T18:16:52.067282Z","iopub.execute_input":"2022-04-11T18:16:52.067910Z","iopub.status.idle":"2022-04-11T18:17:07.027951Z","shell.execute_reply.started":"2022-04-11T18:16:52.067860Z","shell.execute_reply":"2022-04-11T18:17:07.027166Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Implementing early stopping","metadata":{}},{"cell_type":"code","source":"class EarlyStopping(object):\n    def __init__(self, mode='min', min_delta=0, patience=10, percentage=False):\n        self.mode = mode\n        self.min_delta = min_delta\n        self.patience = patience\n        self.best = None\n        self.num_bad_epochs = 0\n        self.is_better = None\n        self._init_is_better(mode, min_delta, percentage)\n        if patience == 0:\n            self.is_better = lambda a, b: True\n            self.step = lambda a: False\n\n    def step(self, metrics):\n        if self.best is None:\n            self.best = metrics\n            return False\n        if np.isnan(metrics):\n            return True\n        if self.is_better(metrics, self.best):\n            self.num_bad_epochs = 0\n            self.best = metrics\n            print('improvement!')\n        else:\n            self.num_bad_epochs += 1\n            print(f'no improvement, bad_epochs counter: {self.num_bad_epochs}')\n        if self.num_bad_epochs >= self.patience:\n            return True\n        return False\n\n    def _init_is_better(self, mode, min_delta, percentage):\n        if mode not in {'min', 'max'}:\n            raise ValueError('mode ' + mode + ' is unknown!')\n        if not percentage:\n            if mode == 'min':\n                self.is_better = lambda a, best: a < best - min_delta\n            if mode == 'max':\n                self.is_better = lambda a, best: a > best + min_delta\n        else:\n            if mode == 'min':\n                self.is_better = lambda a, best: a < best - (\n                            best * min_delta / 100)\n            if mode == 'max':\n                self.is_better = lambda a, best: a > best + (\n                            best * min_delta / 100)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T18:17:07.029298Z","iopub.execute_input":"2022-04-11T18:17:07.029727Z","iopub.status.idle":"2022-04-11T18:17:07.041603Z","shell.execute_reply.started":"2022-04-11T18:17:07.029689Z","shell.execute_reply":"2022-04-11T18:17:07.040901Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Training only the modified parts of the classifier","metadata":{}},{"cell_type":"code","source":"## Fine-tuning the model on our data\nvgg.name = \"VGG\"\n# trainer = Trainer(gpus=min(1, torch.cuda.device_count()),\n#                   max_epochs=3,\n#                   progress_bar_refresh_rate=20,\n#                   callbacks=[EarlyStopping(monitor=\"val_loss\", \n#                                            mode=\"min\", \n#                                            patience=\"5\")])\n# trainer.fit(vgg, VGG_trainloader, VGG_validloader)\nbest_model = train(model=vgg, \n                   epochs=3, \n                   train_loader=VGG_trainloader, \n                   valid_loader=VGG_validloader, \n                   learning_rate=1e-3,\n                   patience=5)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T18:17:07.042870Z","iopub.execute_input":"2022-04-11T18:17:07.043087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking metrics","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving the model in .pth and .onnx extension","metadata":{}},{"cell_type":"code","source":"PATH = \"./\"\ntorch.save(vgg.state_dict(), os.path.join(PATH,\"vgg.pth\"))\nmodel = models.vgg16(pretrained=True)\nmodel.classifier[0] = nn.Linear(25088, 8192)\nmodel.classifier[3] = nn.Linear(8192, 1024)\nmodel.classifier[6] = nn.Linear(1024, 10)\nmodel.load_state_dict(torch.load(os.path.join(PATH,\"vgg.pth\"), map_location='cpu'))\nmodel.eval() \n\ndummy_input = torch.randn(batch_size, 3, input_size, input_size)  \ntorch.onnx.export(model,   \n                  dummy_input, \n                  \"vgg.onnx\",\n                  export_params=True,\n                  do_constant_folding=True, \n                  input_names = ['modelInput'],\n                  output_names = ['modelOutput'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}