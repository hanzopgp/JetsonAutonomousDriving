{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importation","metadata":{"execution":{"iopub.status.busy":"2022-04-11T16:15:07.160836Z","iopub.execute_input":"2022-04-11T16:15:07.161381Z","iopub.status.idle":"2022-04-11T16:15:08.995876Z","shell.execute_reply.started":"2022-04-11T16:15:07.161292Z","shell.execute_reply":"2022-04-11T16:15:08.995057Z"}}},{"cell_type":"code","source":"import os\nimport copy\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom time import time\nfrom sklearn import preprocessing\n\nimport torchvision\nfrom torchvision import models, transforms\nfrom torchvision.io import read_image\n\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torch.utils.data import Dataset\n\nfrom pytorch_lightning import LightningModule, Trainer\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\n\n# !pip install torchvision onnx-coreml\n\n## todo : \n## pytorch oneshot y\n## try sigmoid / none class / threshold on softmax for NONE class","metadata":{"execution":{"iopub.status.busy":"2022-04-13T12:02:35.471839Z","iopub.execute_input":"2022-04-13T12:02:35.472383Z","iopub.status.idle":"2022-04-13T12:02:35.479030Z","shell.execute_reply.started":"2022-04-13T12:02:35.472343Z","shell.execute_reply":"2022-04-13T12:02:35.478269Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Global variables ","metadata":{}},{"cell_type":"code","source":"INPUT_SIZE = 224\nBATCH_SIZE = 128\nN_CLASS = 5\nTRAIN_SPLIT = 0.7\n\nPATH_LABELS = \"../input/homemade-hand-gesture-dataset/index_label.csv\"\nPATH_IMG = \"../input/homemade-hand-gesture-dataset/output/output\"\n\nPATH_LABELS_VALID = \"\"\nPATH_IMG_VALID = \"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-13T12:02:35.835527Z","iopub.execute_input":"2022-04-13T12:02:35.836257Z","iopub.status.idle":"2022-04-13T12:02:35.840850Z","shell.execute_reply.started":"2022-04-13T12:02:35.836215Z","shell.execute_reply":"2022-04-13T12:02:35.840089Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Data functions","metadata":{"execution":{"iopub.status.busy":"2022-04-11T16:20:53.56609Z","iopub.execute_input":"2022-04-11T16:20:53.566375Z","iopub.status.idle":"2022-04-11T16:20:53.569977Z","shell.execute_reply.started":"2022-04-11T16:20:53.566327Z","shell.execute_reply":"2022-04-11T16:20:53.569332Z"}}},{"cell_type":"code","source":"import cv2\n\nclass HandGestureDataset(Dataset):\n    def __init__(self, annotations_file, img_dir, transform=None):\n        self.img_labels = pd.read_csv(annotations_file)\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, os.listdir(self.img_dir)[idx])\n        image = read_image(img_path)\n        label = self.img_labels.loc[self.img_labels[\"index\"] == str(\"output/\"+os.listdir(self.img_dir)[idx])][\"label\"].item()\n        if self.transform:\n            image = self.transform(image)\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2022-04-13T12:02:36.210208Z","iopub.execute_input":"2022-04-13T12:02:36.210741Z","iopub.status.idle":"2022-04-13T12:02:36.218035Z","shell.execute_reply.started":"2022-04-13T12:02:36.210700Z","shell.execute_reply":"2022-04-13T12:02:36.217213Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def prepare_data_vgg(data_type):\n    ## Parameters fitting vgg/imagenet\n    mean=[0.485, 0.456, 0.406]\n    std=[0.229, 0.224, 0.225]\n\n    ## pytorch transformer objects\n    transformVGGTrain=transforms.Compose([\n            transforms.ToPILImage(),\n            transforms.RandomResizedCrop(INPUT_SIZE),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean, std)\n        ])\n#     transformVGGValid=transforms.Compose([\n#             transforms.Resize(INPUT_SIZE),\n#             transforms.CenterCrop(INPUT_SIZE),\n#             transforms.ToTensor(),\n#             transforms.Normalize(mean, std)\n#         ])\n\n    if data_type == \"custom\":\n        ## Custom dataset\n        VGG_dataset = HandGestureDataset(PATH_LABELS, PATH_IMG, transformVGGTrain)\n        print(\"Dataset size:\", len(VGG_dataset))\n        train_size = int(len(VGG_dataset)*(TRAIN_SPLIT))\n        valid_size = len(VGG_dataset) - train_size\n        VGG_trainset, VGG_validset = torch.utils.data.random_split(VGG_dataset, [train_size, valid_size])\n        VGG_trainloader = torch.utils.data.DataLoader(VGG_trainset, batch_size=BATCH_SIZE, pin_memory=True, shuffle=True)\n        VGG_validloader = torch.utils.data.DataLoader(VGG_validset, batch_size=BATCH_SIZE, pin_memory=True, shuffle=True)\n        \n#         VGG_validset = HandGestureDataset(PATH_LABELS_VALID, PATH_IMG_VALID, transformVGGValid)\n#         VGG_validloader = torch.utils.data.DataLoader(VGG_validset, batch_size=BATCH_SIZE, pin_memory=True, shuffle=True)\n    \n    ## CIPHAR10\n    if data_type == \"ciphar10\":\n        VGG_trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transformVGGTrain)\n        VGG_trainloader = torch.utils.data.DataLoader(VGG_trainset, batch_size=BATCH_SIZE, pin_memory=True, shuffle=True)\n        VGG_validset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transformVGGValid)\n        VGG_validloader = torch.utils.data.DataLoader(VGG_validset, batch_size=BATCH_SIZE, pin_memory=True, shuffle=True)\n    \n    return VGG_trainloader, VGG_validloader","metadata":{"execution":{"iopub.status.busy":"2022-04-13T12:02:36.554519Z","iopub.execute_input":"2022-04-13T12:02:36.555172Z","iopub.status.idle":"2022-04-13T12:02:36.564781Z","shell.execute_reply.started":"2022-04-13T12:02:36.555135Z","shell.execute_reply":"2022-04-13T12:02:36.564106Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Loading data into pytorch dataset and dataloader objects","metadata":{"execution":{"iopub.status.busy":"2022-02-15T15:49:41.69497Z","iopub.execute_input":"2022-02-15T15:49:41.695334Z","iopub.status.idle":"2022-02-15T15:49:46.639507Z","shell.execute_reply.started":"2022-02-15T15:49:41.695293Z","shell.execute_reply":"2022-02-15T15:49:46.638679Z"}}},{"cell_type":"code","source":"VGG_trainloader, VGG_validloader = prepare_data_vgg(\"custom\")","metadata":{"execution":{"iopub.status.busy":"2022-04-13T12:02:36.895311Z","iopub.execute_input":"2022-04-13T12:02:36.896210Z","iopub.status.idle":"2022-04-13T12:02:36.919040Z","shell.execute_reply.started":"2022-04-13T12:02:36.896154Z","shell.execute_reply":"2022-04-13T12:02:36.918191Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Model functions","metadata":{}},{"cell_type":"code","source":"def accuracy(yhat,y):\n    if len(y.shape) == 1 or y.size(1) == 1:\n        return (torch.argmax(yhat, 1).view(y.size(0), -1) == y.view(-1, 1)).double().mean()\n    return (torch.argmax(yhat, 1). view(-1) == torch.argmax(y, 1).view(-1)).double().mean()\n\ndef train(model, epochs, train_loader, valid_loader, learning_rate, patience, label_encoder, feature_extract=False):\n    ## Early stopping variables\n    es = EarlyStopping(patience=patience)\n    terminate_training = False\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n     \n    ## TensorBoard setup\n    model = model.to(device)\n    writer = SummaryWriter(f\"{TB_PATH}/{model.name}\")\n    \n    ## Training only the parameters where we require gradient since we are fine-tuning\n    params_to_update = model.parameters()\n    print(\"params to learn:\")\n    if feature_extract:\n        params_to_update = []\n        for name,param in model.named_parameters():\n            if param.requires_grad == True:\n                params_to_update.append(param)\n                print(\"\\t\", name)\n    else:\n        for name,param in model.named_parameters():\n            if param.requires_grad == True:\n                print(\"\\t\", name)\n                \n    ## Setting up our optimizer\n    optim = torch.optim.Adam(params_to_update, lr=learning_rate)\n    \n    ## Setting up our loss function\n    loss = nn.CrossEntropyLoss()\n    \n    ## Running the train loop\n    print(f\"running {model.name}\")\n    for epoch in range(epochs):\n        cumloss, cumacc, count = 0, 0, 0\n        model.train()\n        for x,y in train_loader:\n            optim.zero_grad()\n            x = x.to(device)\n            y = label_encoder.fit_transform(y)\n            y = torch.as_tensor(y)\n#             y = F.one_hot(y, num_classes=N_CLASS)\n            y = y.to(device)\n            yhat = model(x)\n            l = loss(yhat, y)\n            l.backward()\n            optim.step()\n            cumloss += l * len(x)\n            cumacc += accuracy(yhat, y) * len(x)\n            count += len(x)\n#         writer.add_scalar('loss/train', cumloss/count,epoch)\n#         writer.add_scalar('accuracy/train', cumacc/count,epoch)\n        print(\"epoch :\", epoch, end=\"\")\n        print(\", train_loss: \", cumloss.cpu()/count, end=\"\")\n        print(\", train_acc: \", cumacc.cpu()/count, end=\"\")\n        if epoch % 1 == 0:\n            model.eval()\n            with torch.no_grad():\n                valid_cumloss, valid_cumacc, count = 0, 0, 0\n                for x,y in valid_loader:\n                    x = x.to(device)\n                    y = label_encoder.fit_transform(y)\n                    y = torch.as_tensor(y)\n#                     y = F.one_hot(y, num_classes=N_CLASS)\n                    y = y.to(device)\n                    yhat = model(x)\n                    valid_cumloss += loss(yhat,y) * len(x)\n                    valid_cumacc += accuracy(yhat,y) * len(x)\n                    count += len(x)\n#                 writer.add_scalar(f'loss/valid', valid_cumloss/count,epoch)\n#                 writer.add_scalar('accuracy/valid', valid_cumacc/count,epoch)\n                print(\", valid_loss: \", valid_cumloss.cpu()/count, end=\"\")\n                print(\", valid_acc: \", valid_cumacc.cpu()/count)\n                ## Early stopping\n                if valid_cumacc/count > best_acc:\n                    best_acc = valid_cumacc/count\n                    best_model_wts = copy.deepcopy(model.state_dict())\n                if es.step(valid_cumloss.cpu()/count):\n                    terminate_training = True\n                    break\n        if terminate_training:\n            break\n    print('Best val Acc: {:4f}'.format(best_acc))\n    ## Returns the best model\n    model.load_state_dict(best_model_wts)\n    return model\n\ndef set_parameter_requires_grad(model, feature_extract):\n    if feature_extract:\n        for name,p in model.named_parameters():\n            if \"features\" in name:\n                p.requires_grad = False    \n            else:\n                p.requires_grad = True  ","metadata":{"execution":{"iopub.status.busy":"2022-04-13T12:02:37.050771Z","iopub.execute_input":"2022-04-13T12:02:37.052606Z","iopub.status.idle":"2022-04-13T12:02:37.075019Z","shell.execute_reply.started":"2022-04-13T12:02:37.052553Z","shell.execute_reply":"2022-04-13T12:02:37.074258Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Loading the model and modifying the classifier part\n### Maybe we could try to modify only the last classifier layer ?","metadata":{"execution":{"iopub.status.busy":"2022-04-11T16:22:20.614632Z","iopub.execute_input":"2022-04-11T16:22:20.614896Z","iopub.status.idle":"2022-04-11T16:22:20.618197Z","shell.execute_reply.started":"2022-04-11T16:22:20.614868Z","shell.execute_reply":"2022-04-11T16:22:20.617386Z"}}},{"cell_type":"code","source":"TB_PATH = \"/tmp/logs/sceance2\"\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n## Loading vgg16 model pretrained on imagenet\nvgg = models.vgg16(pretrained=True)\n\n## Modifies the vgg network classifier layers to fit our problem\nvgg.classifier[0] = nn.Linear(25088, 8192)\nvgg.classifier[3] = nn.Linear(8192, 1024)\nvgg.classifier[6] = nn.Linear(1024, N_CLASS)\nprint(vgg.eval())\n\n## Sets all the requires grad of the classifier layers to True\nset_parameter_requires_grad(vgg, True)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T12:02:37.099166Z","iopub.execute_input":"2022-04-13T12:02:37.099384Z","iopub.status.idle":"2022-04-13T12:03:03.913708Z","shell.execute_reply.started":"2022-04-13T12:02:37.099357Z","shell.execute_reply":"2022-04-13T12:03:03.912969Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Implementing early stopping","metadata":{}},{"cell_type":"code","source":"class EarlyStopping(object):\n    def __init__(self, mode='min', min_delta=0, patience=10, percentage=False):\n        self.mode = mode\n        self.min_delta = min_delta\n        self.patience = patience\n        self.best = None\n        self.num_bad_epochs = 0\n        self.is_better = None\n        self._init_is_better(mode, min_delta, percentage)\n        if patience == 0:\n            self.is_better = lambda a, b: True\n            self.step = lambda a: False\n\n    def step(self, metrics):\n        if self.best is None:\n            self.best = metrics\n            return False\n        if np.isnan(metrics):\n            return True\n        if self.is_better(metrics, self.best):\n            self.num_bad_epochs = 0\n            self.best = metrics\n#             print('improvement!')\n        else:\n            self.num_bad_epochs += 1\n#             print(f'no improvement, bad_epochs counter: {self.num_bad_epochs}')\n        if self.num_bad_epochs >= self.patience:\n            return True\n        return False\n\n    def _init_is_better(self, mode, min_delta, percentage):\n        if mode not in {'min', 'max'}:\n            raise ValueError('mode ' + mode + ' is unknown!')\n        if not percentage:\n            if mode == 'min':\n                self.is_better = lambda a, best: a < best - min_delta\n            if mode == 'max':\n                self.is_better = lambda a, best: a > best + min_delta\n        else:\n            if mode == 'min':\n                self.is_better = lambda a, best: a < best - (\n                            best * min_delta / 100)\n            if mode == 'max':\n                self.is_better = lambda a, best: a > best + (\n                            best * min_delta / 100)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T12:03:03.915180Z","iopub.execute_input":"2022-04-13T12:03:03.916591Z","iopub.status.idle":"2022-04-13T12:03:03.927771Z","shell.execute_reply.started":"2022-04-13T12:03:03.916550Z","shell.execute_reply":"2022-04-13T12:03:03.927057Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Training only the modified parts of the classifier","metadata":{}},{"cell_type":"code","source":"## Fine-tuning the model on our data\nvgg.name = \"VGG\"\n\nle = preprocessing.LabelEncoder()\n\nbest_model = train(model=vgg, \n                   epochs=100, \n                   train_loader=VGG_trainloader, \n                   valid_loader=VGG_validloader, \n                   learning_rate=1e-3, ## learning rate for Adam optimizer\n                   patience=5, ## metric for earlystopping : val_loss\n                   label_encoder=le) ","metadata":{"execution":{"iopub.status.busy":"2022-04-13T12:03:03.928926Z","iopub.execute_input":"2022-04-13T12:03:03.929219Z","iopub.status.idle":"2022-04-13T12:15:54.260231Z","shell.execute_reply.started":"2022-04-13T12:03:03.929154Z","shell.execute_reply":"2022-04-13T12:15:54.258625Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Checking metrics","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving the model in .pth and .onnx extension","metadata":{}},{"cell_type":"code","source":"PATH = \"./\"\ntorch.save(vgg.state_dict(), os.path.join(PATH,\"vgg.pth\"))","metadata":{"execution":{"iopub.status.busy":"2022-04-13T12:15:54.262237Z","iopub.execute_input":"2022-04-13T12:15:54.262517Z","iopub.status.idle":"2022-04-13T12:15:56.500458Z","shell.execute_reply.started":"2022-04-13T12:15:54.262468Z","shell.execute_reply":"2022-04-13T12:15:56.499667Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"del vgg","metadata":{"execution":{"iopub.status.busy":"2022-04-13T12:15:56.501574Z","iopub.execute_input":"2022-04-13T12:15:56.502353Z","iopub.status.idle":"2022-04-13T12:15:56.506352Z","shell.execute_reply.started":"2022-04-13T12:15:56.502313Z","shell.execute_reply":"2022-04-13T12:15:56.505417Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# model = models.vgg16(pretrained=True)\n# model.classifier[0] = nn.Linear(25088, 8192)\n# model.classifier[3] = nn.Linear(8192, 1024)\n# model.classifier[6] = nn.Linear(1024, N_CLASS)\n# model.load_state_dict(torch.load(os.path.join(PATH,\"vgg.pth\"), map_location='cpu'))\n# model.eval() \n\n# dummy_input = torch.randn(BATCH_SIZE, 3, INPUT_SIZE, INPUT_SIZE)  \n# torch.onnx.export(model,   \n#                   dummy_input, \n#                   \"vgg.onnx\",\n#                   export_params=True,\n#                   do_constant_folding=True, \n#                   input_names = ['modelInput'],\n#                   output_names = ['modelOutput'])","metadata":{"execution":{"iopub.status.busy":"2022-04-13T12:15:56.507784Z","iopub.execute_input":"2022-04-13T12:15:56.508202Z","iopub.status.idle":"2022-04-13T12:15:56.517106Z","shell.execute_reply.started":"2022-04-13T12:15:56.508165Z","shell.execute_reply":"2022-04-13T12:15:56.516366Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}