{"cells":[{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2022-04-11T16:15:07.161381Z","iopub.status.busy":"2022-04-11T16:15:07.160836Z","iopub.status.idle":"2022-04-11T16:15:08.995876Z","shell.execute_reply":"2022-04-11T16:15:08.995057Z","shell.execute_reply.started":"2022-04-11T16:15:07.161292Z"},"id":"NT4f2Kygv7iE"},"source":["# Importation"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T16:51:52.880400Z","iopub.status.busy":"2022-04-25T16:51:52.879623Z","iopub.status.idle":"2022-04-25T16:51:52.899937Z","shell.execute_reply":"2022-04-25T16:51:52.899317Z","shell.execute_reply.started":"2022-04-25T16:51:52.880290Z"},"id":"hhSLshnwwFP1","outputId":"b4db1ea2-e1e1-4338-ab22-511d5c65bd35","trusted":true},"outputs":[],"source":["# ! pip install kaggle\n","# ! mkdir ~/.kaggle\n","# ! cp kaggle.json ~/.kaggle/\n","# ! chmod 600 ~/.kaggle/kaggle.json\n","# ! kaggle datasets download -d enzodurand/boudingboxonlyhanddataset\n","# ! unzip boudingboxonlyhanddataset.zip"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T16:51:52.916243Z","iopub.status.busy":"2022-04-25T16:51:52.915311Z","iopub.status.idle":"2022-04-25T16:51:56.694552Z","shell.execute_reply":"2022-04-25T16:51:56.693404Z","shell.execute_reply.started":"2022-04-25T16:51:52.916199Z"},"id":"BSdwgPVvv7iK","outputId":"9bb2e587-33b2-41cc-9220-f2625433242c","trusted":true},"outputs":[],"source":["import os\n","import copy\n","import cv2\n","# import wandb\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","from time import time\n","from sklearn import preprocessing\n","from matplotlib import pyplot as plt\n","\n","import torchvision\n","from torchvision import models, transforms\n","from torchvision.io import read_image\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import nn\n","from torch.utils.data import Dataset\n","\n","# !pip uninstall albumentations\n","# !pip install albumentations==0.4.6\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2"]},{"cell_type":"markdown","metadata":{"id":"1C5YIPfwzhxp"},"source":["# GPU/TPU setup"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T16:51:56.696909Z","iopub.status.busy":"2022-04-25T16:51:56.696548Z","iopub.status.idle":"2022-04-25T16:51:56.704141Z","shell.execute_reply":"2022-04-25T16:51:56.702265Z","shell.execute_reply.started":"2022-04-25T16:51:56.696864Z"},"id":"vVQzDrNlzfI_","outputId":"d2328c3e-a835-4f78-af06-fc5339afac63","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n"]}],"source":["## TPU\n","# !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n","# !python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev\n","# import torch_xla\n","# import torch_xla.core.xla_model as xm\n","# device = xm.xla_device()\n","# torch.set_default_tensor_type('torch.FloatTensor')\n","\n","## GPU\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","## Weight and biases\n","# wandb.login()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T16:51:56.706664Z","iopub.status.busy":"2022-04-25T16:51:56.705743Z","iopub.status.idle":"2022-04-25T16:51:57.461217Z","shell.execute_reply":"2022-04-25T16:51:57.460116Z","shell.execute_reply.started":"2022-04-25T16:51:56.706613Z"},"id":"CfM_nSBaiXcB","outputId":"9e21e657-01d3-4e87-8ec7-ace6895e068f","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon Apr 25 19:02:54 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 511.65       Driver Version: 511.65       CUDA Version: 11.6     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n","| N/A   67C    P8     5W /  N/A |      0MiB /  6144MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|    0   N/A  N/A      1524    C+G   C:\\Windows\\System32\\dwm.exe     N/A      |\n","|    0   N/A  N/A      6868    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n","|    0   N/A  N/A     11812    C+G   C:\\Windows\\explorer.exe         N/A      |\n","|    0   N/A  N/A     19472    C+G   ...arp.BrowserSubprocess.exe    N/A      |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"1jRIVkpdv7iM"},"source":["# Global variables "]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T16:51:57.464302Z","iopub.status.busy":"2022-04-25T16:51:57.463990Z","iopub.status.idle":"2022-04-25T16:51:57.468949Z","shell.execute_reply":"2022-04-25T16:51:57.468177Z","shell.execute_reply.started":"2022-04-25T16:51:57.464253Z"},"id":"huwjGSaZv7iN","trusted":true},"outputs":[],"source":["INPUT_SIZE = 400\n","N_CLASS = 4\n","WHERE = \"home\""]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T16:51:57.470440Z","iopub.status.busy":"2022-04-25T16:51:57.470185Z","iopub.status.idle":"2022-04-25T16:51:57.480388Z","shell.execute_reply":"2022-04-25T16:51:57.479745Z","shell.execute_reply.started":"2022-04-25T16:51:57.470412Z"},"id":"e-dNYYCyz8E4","trusted":true},"outputs":[],"source":["if WHERE==\"colab\":\n","    PATH_LABELS = \"/content/index_label_bbox.csv\"\n","    PATH_IMG = \"/content/output/output\"\n","    PATH_LABELS_VALID = \"/content/index_label_bbox_validation.csv\"\n","    PATH_IMG_VALID = \"/content/output_validation/output_validation\"\n","    BATCH_SIZE = 32\n","elif WHERE==\"kaggle\":\n","    PATH_LABELS = \"../input/boudingboxonlyhanddataset/index_label_bbox.csv\"\n","    PATH_IMG = \"../input/boudingboxonlyhanddataset/output/output\"\n","    PATH_LABELS_VALID = \"../input/boudingboxonlyhanddataset/index_label_bbox_validation.csv\"\n","    PATH_IMG_VALID = \"../input/boudingboxonlyhanddataset/output_validation/output_validation\"\n","    BATCH_SIZE = 64\n","elif WHERE==\"home\":\n","    PATH_LABELS = \"../../../data_labels/bounding_box_model/done/index_label_bbox.csv\"\n","    PATH_IMG = \"../../../data_labels/bounding_box_model/done/output\"\n","    PATH_LABELS_VALID = \"../../../data_labels/bounding_box_model/done_validation/index_label_bbox_validation.csv\"\n","    PATH_IMG_VALID = \"../../../data_labels/bounding_box_model/done_validation/output_validation\"\n","    BATCH_SIZE = 4"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2022-04-11T16:20:53.566375Z","iopub.status.busy":"2022-04-11T16:20:53.56609Z","iopub.status.idle":"2022-04-11T16:20:53.569977Z","shell.execute_reply":"2022-04-11T16:20:53.569332Z","shell.execute_reply.started":"2022-04-11T16:20:53.566327Z"},"id":"nSGukie2v7iN"},"source":["# Data functions"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T16:59:23.353741Z","iopub.status.busy":"2022-04-25T16:59:23.352820Z","iopub.status.idle":"2022-04-25T16:59:23.365845Z","shell.execute_reply":"2022-04-25T16:59:23.364496Z","shell.execute_reply.started":"2022-04-25T16:59:23.353693Z"},"id":"uwmn_pJKv7iO","trusted":true},"outputs":[],"source":["class HandGestureDataset(Dataset):\n","    def __init__(self, annotations_file, img_dir, transform=None):\n","        self.img_labels = pd.read_csv(annotations_file)\n","        self.img_dir = img_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.img_labels)\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.img_dir, os.listdir(self.img_dir)[idx])\n","        image = read_image(img_path)\n","        path = str(\"output/\"+os.listdir(self.img_dir)[idx]).split(\"/\")[0]\n","        line = self.img_labels[\"index\"] == str(path+\"/\"+os.listdir(self.img_dir)[idx])\n","        x, y, x_end, y_end = self.img_labels.loc[line][\"x\"].item(),\\\n","                                self.img_labels.loc[line][\"y\"].item(),\\\n","                                self.img_labels.loc[line][\"x_end\"].item(),\\\n","                                self.img_labels.loc[line][\"y_end\"].item()\n","        x, y, x_end, y_end = x/INPUT_SIZE, y/INPUT_SIZE, x_end/INPUT_SIZE, y_end/INPUT_SIZE\n","        \n","        image = image/255\n","        \n","#         image = image.permute(1,2,0)\n","#         if self.transform:\n","#             transformed = self.transform(image=np.array(image), bboxes=[[x,y,x_end,y_end]])\n","#         transformed_image = transformed['image']\n","#         transformed_bboxes = transformed['bboxes']\n","#         return transformed_image, transformed_bboxes\n","\n","        if self.transform:\n","            transformed = self.transform(image)\n","        label = [x, y, x_end, y_end]\n","        return {\"image\":image, \"label\":label}"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T16:59:24.109486Z","iopub.status.busy":"2022-04-25T16:59:24.108848Z","iopub.status.idle":"2022-04-25T16:59:24.129562Z","shell.execute_reply":"2022-04-25T16:59:24.128498Z","shell.execute_reply.started":"2022-04-25T16:59:24.109419Z"},"id":"VQreQL2ov7iP","trusted":true},"outputs":[],"source":["def draw_predictions(image, preds):\n","    startX, startY, endX, endY = preds\n","    # scale the predicted bounding box coordinates based on the image\n","    # dimensions    \n","    startX = int(startX * INPUT_SIZE)\n","    startY = int(startY * INPUT_SIZE)\n","    endX = int(endX * INPUT_SIZE)\n","    endY = int(endY * INPUT_SIZE)\n","#     print(startX, startY, endX, endY)\n","    # draw the predicted bounding box on the image\n","    image = image.numpy().copy()\n","    cv2.rectangle(image, (startX, startY), (endX, endY), (0, 255, 0), 2)\n","    # show the output image\n","    plt.imshow(image)\n","    plt.show()\n","\n","def prepare_data_vgg(data_type):\n","    ## Parameters fitting vgg/imagenet\n","    mean=[0.485, 0.456, 0.406]\n","    std=[0.229, 0.224, 0.225]\n","\n","    transformVGGTrainAlbu = A.Compose([\n","        A.VerticalFlip(p=0.3),\n","        A.HorizontalFlip(p=0.5),\n","        A.Blur(p=0.3, blur_limit=5),\n","        A.RandomBrightnessContrast(p=0.3),\n","        A.RandomGamma(p=0.3),\n","        A.ChannelShuffle(p=0.3),\n","        A.Rotate(p=0.5, limit=60),\n","#         A.Downscale(p=0.3, scale_min=0.6, scale_max=0.9),\n","#         A.ShiftScaleRotate(p=0.3),\n","#         A.ElasticTransform(p=0.3, border_mode=cv2.BORDER_REFLECT_101, alpha_affine=40),\n","#         A.RGBShift(r_shift_limit=0.3, g_shift_limit=0.3, b_shift_limit=30, p=0.3),\n","#         A.Normalize(mean=mean, std=std),\n","        A.Resize(INPUT_SIZE, INPUT_SIZE, p=1),\n","        ToTensorV2(),\n","    ], bbox_params=A.BboxParams(format='albumentations', label_fields=\"\"))\n","    transformVGGValidAlbu = A.Compose([\n","#         A.Normalize(mean=mean, std=std),\n","        A.Resize(INPUT_SIZE, INPUT_SIZE, p=1),\n","        ToTensorV2(),\n","    ], bbox_params=A.BboxParams(format='albumentations', label_fields=\"\"))\n","    \n","    transformVGGTrain = torchvision.transforms.Compose([\n","        torchvision.transforms.ToPILImage(),\n","        torchvision.transforms.Resize(size=(INPUT_SIZE, INPUT_SIZE)),\n","        torchvision.transforms.ToTensor(),\n","    ])\n","    transformVGGValid = torchvision.transforms.Compose([\n","        torchvision.transforms.ToPILImage(),\n","        torchvision.transforms.Resize(size=(INPUT_SIZE, INPUT_SIZE)),\n","        torchvision.transforms.ToTensor(),\n","    ])\n","\n","    if data_type == \"custom\":\n","        ## Custom dataset\n","#         VGG_dataset_train = HandGestureDataset(PATH_LABELS, PATH_IMG, transformVGGTrainAlbu)\n","#         VGG_dataset_valid = HandGestureDataset(PATH_LABELS_VALID, PATH_IMG_VALID, transformVGGValidAlbu)\n","        VGG_dataset_train = HandGestureDataset(PATH_LABELS, PATH_IMG, transformVGGTrain)\n","        VGG_dataset_valid = HandGestureDataset(PATH_LABELS_VALID, PATH_IMG_VALID, transformVGGValid)\n","        VGG_trainloader = torch.utils.data.DataLoader(VGG_dataset_train, batch_size=BATCH_SIZE, pin_memory=True, shuffle=True)\n","        VGG_validloader = torch.utils.data.DataLoader(VGG_dataset_valid, batch_size=BATCH_SIZE, pin_memory=True, shuffle=True)\n","\n","    return VGG_trainloader, VGG_validloader"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2022-02-15T15:49:41.695334Z","iopub.status.busy":"2022-02-15T15:49:41.69497Z","iopub.status.idle":"2022-02-15T15:49:46.639507Z","shell.execute_reply":"2022-02-15T15:49:46.638679Z","shell.execute_reply.started":"2022-02-15T15:49:41.695293Z"},"id":"I7EYl1LCv7iQ"},"source":["# Loading data into pytorch dataset and dataloader objects"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T16:59:24.809215Z","iopub.status.busy":"2022-04-25T16:59:24.808669Z","iopub.status.idle":"2022-04-25T16:59:24.827504Z","shell.execute_reply":"2022-04-25T16:59:24.826739Z","shell.execute_reply.started":"2022-04-25T16:59:24.809166Z"},"id":"gSLUtb3rv7iQ","trusted":true},"outputs":[],"source":["VGG_trainloader, VGG_validloader = prepare_data_vgg(\"custom\")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T16:59:25.102032Z","iopub.status.busy":"2022-04-25T16:59:25.101729Z","iopub.status.idle":"2022-04-25T16:59:25.106280Z","shell.execute_reply":"2022-04-25T16:59:25.105662Z","shell.execute_reply.started":"2022-04-25T16:59:25.102003Z"},"id":"Dxv-Unzwv7iR","trusted":true},"outputs":[],"source":["# for img, bbox in VGG_trainloader:\n","#     res = []\n","#     for e in bbox:\n","#         res_ = []\n","#         for elt in e:\n","#             res_.append(elt.numpy())\n","#         res.append(np.array(res_))\n","#     res = np.array(res).T.squeeze()\n","#     cpt = 0\n","#     for i, l in zip(img, res):\n","#         draw_predictions(i.permute(1,2,0), l)\n","\n","# for img, bbox in VGG_validloader:\n","#     res = []\n","#     for e in bbox:\n","#         res_ = []\n","#         for elt in e:\n","#             res_.append(elt.numpy())\n","#         res.append(np.array(res_))\n","#     res = np.array(res).T.squeeze()\n","#     cpt = 0\n","#     for i, l in zip(img, res):\n","#         draw_predictions(i.permute(1,2,0), l)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T16:59:25.238702Z","iopub.status.busy":"2022-04-25T16:59:25.237933Z","iopub.status.idle":"2022-04-25T16:59:25.243080Z","shell.execute_reply":"2022-04-25T16:59:25.242450Z","shell.execute_reply.started":"2022-04-25T16:59:25.238663Z"},"trusted":true},"outputs":[],"source":["# for item in VGG_trainloader:\n","#     x, y = item[\"image\"], item[\"label\"]\n","#     base_img = item[\"image\"]\n","#     x = item[\"image\"].to(device)\n","#     res = []\n","#     for e in y:\n","#         res.append(np.array(e))\n","#     res = np.array(res).T\n","#     y = torch.as_tensor(res)\n","#     y = y.to(torch.float32)\n","#     y = y.to(device)\n","#     for i in range(4):\n","#         draw_predictions(base_img[i].permute(1,2,0), y.cpu()[i])"]},{"cell_type":"markdown","metadata":{"id":"0yNIY1tPv7iR"},"source":["# Model functions"]},{"cell_type":"code","execution_count":13,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-04-25T16:59:25.621606Z","iopub.status.busy":"2022-04-25T16:59:25.621011Z","iopub.status.idle":"2022-04-25T16:59:25.630857Z","shell.execute_reply":"2022-04-25T16:59:25.629856Z","shell.execute_reply.started":"2022-04-25T16:59:25.621554Z"},"id":"TmOsJNGTv7iS","trusted":true},"outputs":[],"source":["# def train(model, epochs, train_loader, valid_loader, learning_rate, patience, feature_extract=False):\n","#     ## Early stopping variables\n","#     es = EarlyStopping(patience=patience)\n","#     terminate_training = False\n","#     best_model_wts = copy.deepcopy(model.state_dict())\n","#     best_loss = np.inf\n","#     model = model.to(device)\n","#     ## Training only the parameters where we require gradient since we are fine-tuning\n","#     params_to_update = model.parameters()\n","#     print(\"params to learn:\")\n","#     if feature_extract:\n","#         params_to_update = []\n","#         for name,param in model.named_parameters():\n","#             if param.requires_grad == True:\n","#                 params_to_update.append(param)\n","#                 print(\"\\t\", name)\n","#     else:\n","#         for name,param in model.named_parameters():\n","#             if param.requires_grad == True:\n","#                 print(\"\\t\", name)\n","                \n","#     ## Setting up our optimizer\n","#     optim = torch.optim.Adam(params_to_update, lr=learning_rate)\n","\n","#     ## Setting up our loss function\n","#     loss = nn.MSELoss()\n","\n","#     ## Running the train loop\n","#     print(f\"running {model.name}\")\n","#     for epoch in range(epochs):\n","#         cumloss, count = 0, 0\n","#         model.train()\n","#         for x,y in train_loader:\n","#             optim.zero_grad()\n","#             x = x.to(device)\n","#             x = x.float()\n","#             res = []\n","#             for e in y:\n","#                 res_ = []\n","#                 for elt in e:\n","#                     res_.append(elt.numpy())\n","#                 res.append(np.array(res_))\n","#             res = np.array(res).T.squeeze()\n","# #             print(\"/\"*20)\n","# #             print(res)\n","# #             print(\"/\"*20)\n","#             y = torch.as_tensor(res)\n","#             y = y.to(torch.float32)\n","#             y = y.to(device)\n","#             yhat = model(x)\n","#             l = loss(yhat, y)\n","#             l.backward()\n","#             # xm.optimizer_step(optim, barrier=True)\n","#             optim.step()\n","#             cumloss += l * len(x)\n","#             count += len(x)\n","#         print(\"epoch :\", epoch, end=\"\")\n","#         loss_ = cumloss.cpu().item()/count\n","# #         wandb.log({'train_loss': loss_})\n","#         print(\", train_loss: \", loss_, end=\"\")\n","#         if epoch % 1 == 0:\n","#             model.eval()\n","#             with torch.no_grad():\n","#                 valid_cumloss, count = 0, 0\n","#                 for x,y in valid_loader:\n","#                     x = x.to(device)\n","#                     x = x.float()\n","#                     res = []\n","#                     for e in y:\n","#                         res_ = []\n","#                         for elt in e:\n","#                             res_.append(elt.numpy())\n","#                         res.append(np.array(res_))\n","#                     res = np.array(res).T.squeeze()\n","# #                     print(\"ù\"*20)\n","# #                     print(res)\n","# #                     print(\"ù\"*20)\n","#                     y = torch.as_tensor(res)\n","#                     y = y.to(torch.float32)\n","#                     y = y.to(device)\n","#                     yhat = model(x)\n","#                     valid_cumloss += loss(yhat,y) * len(x)\n","#                     count += len(x)\n","#                 valid_loss_ = valid_cumloss.cpu().item()/count\n","# #                 wandb.log({'valid_loss': valid_loss_})\n","#                 print(\", valid_loss: \", valid_loss_)\n","#                 ## Early stopping\n","#                 if valid_cumloss/count < best_loss:\n","#                     best_loss = valid_cumloss/count\n","#                     best_model_wts = copy.deepcopy(model.state_dict())\n","#                 if es.step(valid_cumloss.cpu().item()/count):\n","#                     terminate_training = True\n","#                     break\n","#         if terminate_training:\n","#             break\n","#     print('Best val loss: {:4f}'.format(best_loss))\n","#     ## Returns the best model\n","#     model.load_state_dict(best_model_wts)\n","#     return model\n","\n","# def set_parameter_requires_grad(model, feature_extract):\n","#     if feature_extract:\n","#         for name,p in model.named_parameters():\n","#             if \"features\" in name:\n","#                 p.requires_grad = False    \n","#             else:\n","#                 p.requires_grad = True  "]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T16:59:25.985421Z","iopub.status.busy":"2022-04-25T16:59:25.984928Z","iopub.status.idle":"2022-04-25T16:59:26.007455Z","shell.execute_reply":"2022-04-25T16:59:26.006665Z","shell.execute_reply.started":"2022-04-25T16:59:25.985373Z"},"trusted":true},"outputs":[],"source":["def train(model, epochs, train_loader, valid_loader, learning_rate, patience, feature_extract=False):\n","    ## Early stopping variables\n","    es = EarlyStopping(patience=patience)\n","    terminate_training = False\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_loss = np.inf\n","    model = model.to(device)\n","    ## Training only the parameters where we require gradient since we are fine-tuning\n","    params_to_update = model.parameters()\n","    print(\"params to learn:\")\n","    if feature_extract:\n","        params_to_update = []\n","        for name,param in model.named_parameters():\n","            if param.requires_grad == True:\n","                params_to_update.append(param)\n","                print(\"\\t\", name)\n","    else:\n","        for name,param in model.named_parameters():\n","            if param.requires_grad == True:\n","                print(\"\\t\", name)\n","                \n","    ## Setting up our optimizer\n","    optim = torch.optim.Adam(params_to_update, lr=learning_rate)\n","\n","    ## Setting up our loss function\n","    loss = nn.MSELoss()\n","\n","    ## Running the train loop\n","    print(f\"running {model.name}\")\n","    for epoch in range(epochs):\n","        cumloss, count = 0, 0\n","        model.train()\n","        for item in train_loader:\n","            x, y = item[\"image\"], item[\"label\"]\n","            x = x.to(device)\n","            res = []\n","            for e in y:\n","                res.append(np.array(e))\n","            res = np.array(res).T\n","            y = torch.as_tensor(res)\n","            y = y.to(torch.float32)\n","            y = y.to(device)\n","#             print(x.shape)\n","#             print(x)\n","            yhat = model(x)\n","            l = loss(yhat, y)\n","            l.backward()\n","            # xm.optimizer_step(optim, barrier=True)\n","            optim.step()\n","            cumloss += l * len(x)\n","            count += len(x)\n","        print(\"epoch :\", epoch, end=\"\")\n","        loss_ = cumloss.cpu().item()/count\n","#         wandb.log({'train_loss': loss_})\n","        print(\", train_loss: \", loss_, end=\"\")\n","        if epoch % 1 == 0:\n","            model.eval()\n","            with torch.no_grad():\n","                valid_cumloss, count = 0, 0\n","                for item in valid_loader:\n","                    x, y = item[\"image\"], item[\"label\"]\n","                    x = x.to(device)\n","                    res = []\n","                    for e in y:\n","                        res.append(np.array(e))\n","                    res = np.array(res).T\n","                    y = torch.as_tensor(res)\n","                    y = y.to(torch.float32)\n","                    y = y.to(device)\n","                    yhat = model(x)\n","                    valid_cumloss += loss(yhat,y) * len(x)\n","                    count += len(x)\n","                valid_loss_ = valid_cumloss.cpu().item()/count\n","#                 wandb.log({'valid_loss': valid_loss_})\n","                print(\", valid_loss: \", valid_loss_)\n","                ## Early stopping\n","                if valid_cumloss/count < best_loss:\n","                    best_loss = valid_cumloss/count\n","                    best_model_wts = copy.deepcopy(model.state_dict())\n","                if es.step(valid_cumloss.cpu().item()/count):\n","                    terminate_training = True\n","                    break\n","        if terminate_training:\n","            break\n","    print('Best val loss: {:4f}'.format(best_loss))\n","    ## Returns the best model\n","    model.load_state_dict(best_model_wts)\n","    return model\n","\n","def set_parameter_requires_grad(model, feature_extract):\n","    if feature_extract:\n","        for name,p in model.named_parameters():\n","            if \"features\" in name:\n","                p.requires_grad = False    \n","            else:\n","                p.requires_grad = True  "]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2022-04-11T16:22:20.614896Z","iopub.status.busy":"2022-04-11T16:22:20.614632Z","iopub.status.idle":"2022-04-11T16:22:20.618197Z","shell.execute_reply":"2022-04-11T16:22:20.617386Z","shell.execute_reply.started":"2022-04-11T16:22:20.614868Z"},"id":"LdrT-bVhv7iS"},"source":["# Loading the model and modifying the classifier part"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T16:59:26.749121Z","iopub.status.busy":"2022-04-25T16:59:26.748818Z","iopub.status.idle":"2022-04-25T16:59:30.664554Z","shell.execute_reply":"2022-04-25T16:59:30.663497Z","shell.execute_reply.started":"2022-04-25T16:59:26.749090Z"},"id":"X_bEUNDLv7iT","outputId":"74d04a24-a4b5-436c-a9d9-8cae0997a8e2","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=4096, out_features=1024, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=1024, out_features=256, bias=True)\n","    (5): ReLU()\n","    (6): Linear(in_features=256, out_features=4, bias=True)\n","    (7): Sigmoid()\n","  )\n",")\n"]}],"source":["## Loading vgg16 model pretrained on imagenet\n","vgg = models.vgg16(pretrained=True)\n","\n","vgg.classifier = nn.Sequential(nn.Linear(25088, 4096), \n","                               nn.ReLU(), \n","                            #    nn.Dropout(0.5),        \n","                               nn.Linear(4096, 1024), \n","                               nn.ReLU(), \n","                            #    nn.Dropout(0.5),        \n","                               nn.Linear(1024, 256),\n","                               nn.ReLU(), \n","                            #    nn.Dropout(0.5),        \n","                               nn.Linear(256, N_CLASS),\n","                               nn.Sigmoid())\n","\n","print(vgg.eval())\n","\n","## Sets all the requires grad of the classifier layers to True\n","set_parameter_requires_grad(vgg, True)"]},{"cell_type":"markdown","metadata":{"id":"oiqed-DRv7iT"},"source":["# Implementing early stopping"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T16:59:30.667140Z","iopub.status.busy":"2022-04-25T16:59:30.666827Z","iopub.status.idle":"2022-04-25T16:59:30.680791Z","shell.execute_reply":"2022-04-25T16:59:30.679809Z","shell.execute_reply.started":"2022-04-25T16:59:30.667099Z"},"id":"N4pImz6Av7iU","trusted":true},"outputs":[],"source":["class EarlyStopping(object):\n","    def __init__(self, mode='min', min_delta=0, patience=10, percentage=False):\n","        self.mode = mode\n","        self.min_delta = min_delta\n","        self.patience = patience\n","        self.best = None\n","        self.num_bad_epochs = 0\n","        self.is_better = None\n","        self._init_is_better(mode, min_delta, percentage)\n","        if patience == 0:\n","            self.is_better = lambda a, b: True\n","            self.step = lambda a: False\n","\n","    def step(self, metrics):\n","        if self.best is None:\n","            self.best = metrics\n","            return False\n","        if np.isnan(metrics):\n","            return True\n","        if self.is_better(metrics, self.best):\n","            self.num_bad_epochs = 0\n","            self.best = metrics\n","        else:\n","            self.num_bad_epochs += 1\n","        if self.num_bad_epochs >= self.patience:\n","            return True\n","        return False\n","\n","    def _init_is_better(self, mode, min_delta, percentage):\n","        if mode not in {'min', 'max'}:\n","            raise ValueError('mode ' + mode + ' is unknown!')\n","        if not percentage:\n","            if mode == 'min':\n","                self.is_better = lambda a, best: a < best - min_delta\n","            if mode == 'max':\n","                self.is_better = lambda a, best: a > best + min_delta\n","        else:\n","            if mode == 'min':\n","                self.is_better = lambda a, best: a < best - (\n","                            best * min_delta / 100)\n","            if mode == 'max':\n","                self.is_better = lambda a, best: a > best + (\n","                            best * min_delta / 100)"]},{"cell_type":"markdown","metadata":{"id":"tRpWlPvEv7iU"},"source":["# Training only the modified parts of the classifier"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T16:59:30.682278Z","iopub.status.busy":"2022-04-25T16:59:30.682069Z","iopub.status.idle":"2022-04-25T16:59:30.697467Z","shell.execute_reply":"2022-04-25T16:59:30.696561Z","shell.execute_reply.started":"2022-04-25T16:59:30.682252Z"},"id":"46vOGoBkecro","trusted":true},"outputs":[],"source":["# os.environ['WANDB_NOTEBOOK_NAME'] = '4096_5e-6'\n","# wandb.init(project=\"jetson-autonomous-driving\")"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T16:59:30.699529Z","iopub.status.busy":"2022-04-25T16:59:30.699288Z","iopub.status.idle":"2022-04-25T17:00:01.049023Z","shell.execute_reply":"2022-04-25T17:00:01.048087Z","shell.execute_reply.started":"2022-04-25T16:59:30.699498Z"},"id":"JXlDQQfhv7iV","outputId":"9e28c8a1-b134-4f27-d9da-e440e1d4bef0","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["536\n","151\n","params to learn:\n","\t classifier.0.weight\n","\t classifier.0.bias\n","\t classifier.2.weight\n","\t classifier.2.bias\n","\t classifier.4.weight\n","\t classifier.4.bias\n","\t classifier.6.weight\n","\t classifier.6.bias\n","running VGG\n","epoch : 0, train_loss:  0.043847247735777896, valid_loss:  0.041951097127211054\n","epoch : 1, train_loss:  0.023530193229219808, valid_loss:  0.03046403612409319\n","epoch : 2, train_loss:  0.017276680291588627, valid_loss:  0.037674102276266615\n","epoch : 3, train_loss:  0.014552805850754923, valid_loss:  0.027346851817793227\n","epoch : 4, train_loss:  0.011532006868675573, valid_loss:  0.02592500420503838\n","epoch : 5, train_loss:  0.009839233177811352, valid_loss:  0.026187801677919304\n","epoch : 6, train_loss:  0.008495748932681867, valid_loss:  0.029846137544245418\n","epoch : 7, train_loss:  0.0077325185733055, valid_loss:  0.024242180922498736\n","epoch : 8, train_loss:  0.007385311286840866, valid_loss:  0.027686660867988867\n","epoch : 9, train_loss:  0.006651598126140993, valid_loss:  0.02585089642344123\n","epoch : 10, train_loss:  0.006554080479180635, valid_loss:  0.02624902535118534\n","epoch : 11, train_loss:  0.00653927317306177, valid_loss:  0.025968678369870615\n","epoch : 12, train_loss:  0.0069335485572245585, valid_loss:  0.024756658116844407\n","epoch : 13, train_loss:  0.007416976031972401, valid_loss:  0.023430841705727814\n","epoch : 14, train_loss:  0.008180824678335617, valid_loss:  0.02558719280154206\n","epoch : 15, train_loss:  0.009061117670429287, valid_loss:  0.025477664415226427\n","epoch : 16, train_loss:  0.00779831943227284, valid_loss:  0.025434806101345936\n","epoch : 17, train_loss:  0.007901806439926376, valid_loss:  0.027487612245882864\n","epoch : 18, train_loss:  0.008014086467116627, valid_loss:  0.022477679078365086\n","epoch : 19, train_loss:  0.007870325401647766, valid_loss:  0.025189829031098326\n","epoch : 20, train_loss:  0.008391082286834717, valid_loss:  0.021930643886426755\n","epoch : 21, train_loss:  0.00894703438032919, valid_loss:  0.02171578201344639\n","epoch : 22, train_loss:  0.00817252184028056, valid_loss:  0.024340456902386738\n","epoch : 23, train_loss:  0.008092074251886624, valid_loss:  0.01979802850869011\n","epoch : 24, train_loss:  0.008234650341432486, valid_loss:  0.024383213828964488\n","epoch : 25, train_loss:  0.007750351927173671, valid_loss:  0.025229397010169553\n","epoch : 26, train_loss:  0.008005794304520336, valid_loss:  0.024840673338931266\n","epoch : 27, train_loss:  0.007620816800131726, valid_loss:  0.024192746691529536\n","epoch : 28, train_loss:  0.007819720168611896, valid_loss:  0.022905585773759507\n","epoch : 29, train_loss:  0.007726220052633712, valid_loss:  0.021796765121510655\n"]}],"source":["print(len(VGG_trainloader))\n","print(len(VGG_validloader))\n","\n","## Fine-tuning the model on our data\n","vgg.name = \"VGG\"\n","\n","best_model = train(model=vgg, \n","                   epochs=1000, \n","                   train_loader=VGG_trainloader, \n","                   valid_loader=VGG_validloader, \n","                   learning_rate=5e-5,\n","                   patience=20) ## metric for earlystopping : val_loss "]},{"cell_type":"markdown","metadata":{"id":"9_RQMAV0v7iV"},"source":["# Checking predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-04-25T16:51:57.744721Z","iopub.status.idle":"2022-04-25T16:51:57.745440Z","shell.execute_reply":"2022-04-25T16:51:57.745292Z","shell.execute_reply.started":"2022-04-25T16:51:57.745274Z"},"id":"FDqVuSEIv7iW","trusted":true},"outputs":[],"source":["# with torch.no_grad():\n","#     for item in VGG_trainloader:\n","#         x, y = item[\"image\"], item[\"label\"]\n","#         base_img = item[\"image\"]\n","#         x = item[\"image\"].to(device)\n","#         res = []\n","#         for e in y:\n","#             res.append(np.array(e))\n","#         res = np.array(res).T\n","#         y = torch.as_tensor(res)\n","#         y = y.to(torch.float32)\n","#         y = y.to(device)\n","#         yhat = best_model(x)\n","#         for i in range(4):\n","#             draw_predictions(base_img[i].permute(1,2,0), yhat.cpu()[i])\n","\n","with torch.no_grad():\n","    for x, y in VGG_validloader:\n","        x = x.to(device)\n","        x = x.float()\n","        yhat = best_model(x)\n","        for i in range(4):\n","            draw_predictions(x[i].cpu().permute(1,2,0), yhat.cpu()[i])"]},{"cell_type":"markdown","metadata":{"id":"yOuDvy_7v7iW"},"source":["# Saving the model in .pth and .onnx extension"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-04-25T16:51:57.746269Z","iopub.status.idle":"2022-04-25T16:51:57.746632Z","shell.execute_reply":"2022-04-25T16:51:57.746455Z","shell.execute_reply.started":"2022-04-25T16:51:57.746433Z"},"id":"69YZ-O8Pv7iW","trusted":true},"outputs":[],"source":["PATH = \"./\"\n","torch.save(best_model.state_dict(), os.path.join(PATH,\"boundingbox_vgg_last.pth\"))\n","# from google.colab import files\n","# files.download(os.path.join(PATH,\"boundingbox_vgg_last.pth\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-04-25T16:51:57.747810Z","iopub.status.idle":"2022-04-25T16:51:57.748463Z","shell.execute_reply":"2022-04-25T16:51:57.748292Z","shell.execute_reply.started":"2022-04-25T16:51:57.748271Z"},"id":"k3zZ0xCAv7iX","trusted":true},"outputs":[],"source":["# del vgg\n","# del best_model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-04-25T16:51:57.749608Z","iopub.status.idle":"2022-04-25T16:51:57.749910Z","shell.execute_reply":"2022-04-25T16:51:57.749774Z","shell.execute_reply.started":"2022-04-25T16:51:57.749758Z"},"id":"fhRGHT_zv7iX","trusted":true},"outputs":[],"source":["# model = models.vgg16(pretrained=True)\n","# model.classifier[0] = nn.Linear(25088, 8192)\n","# model.classifier[3] = nn.Linear(8192, 1024)\n","# model.classifier[6] = nn.Linear(1024, N_CLASS)\n","# model.load_state_dict(torch.load(os.path.join(PATH,\"vgg.pth\"), map_location='cpu'))\n","# model.eval() \n","\n","# dummy_input = torch.randn(BATCH_SIZE, 3, INPUT_SIZE, INPUT_SIZE)  \n","# torch.onnx.export(model,   \n","#                   dummy_input, \n","#                   \"vgg.onnx\",\n","#                   export_params=True,\n","#                   do_constant_folding=True, \n","#                   input_names = ['modelInput'],\n","#                   output_names = ['modelOutput'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3nyDFGuUv7iX"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DLpVF-Vov7iX"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":4}
