{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-11T16:15:07.161381Z",
          "iopub.status.busy": "2022-04-11T16:15:07.160836Z",
          "iopub.status.idle": "2022-04-11T16:15:08.995876Z",
          "shell.execute_reply": "2022-04-11T16:15:08.995057Z",
          "shell.execute_reply.started": "2022-04-11T16:15:07.161292Z"
        },
        "id": "NT4f2Kygv7iE"
      },
      "source": [
        "# Importation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hhSLshnwwFP1"
      },
      "outputs": [],
      "source": [
        "# ! pip install kaggle\n",
        "# ! mkdir ~/.kaggle\n",
        "# ! cp kaggle.json ~/.kaggle/\n",
        "# ! chmod 600 ~/.kaggle/kaggle.json\n",
        "# ! kaggle datasets download -d enzodurand/boudingboxonlyhanddataset\n",
        "# ! unzip boudingboxonlyhanddataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-18T11:58:07.911562Z",
          "iopub.status.busy": "2022-04-18T11:58:07.910544Z",
          "iopub.status.idle": "2022-04-18T11:58:11.223143Z",
          "shell.execute_reply": "2022-04-18T11:58:11.221959Z",
          "shell.execute_reply.started": "2022-04-18T11:58:07.911406Z"
        },
        "id": "BSdwgPVvv7iK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import copy\n",
        "import cv2\n",
        "import wandb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from time import time\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import f1_score \n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "from torchvision.io import read_image\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# !pip install albumentations\n",
        "import albumentations as A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C5YIPfwzhxp"
      },
      "source": [
        "# GPU/TPU setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vVQzDrNlzfI_"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhanzopgp\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## TPU\n",
        "# !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "# !python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev\n",
        "# import torch_xla\n",
        "# import torch_xla.core.xla_model as xm\n",
        "# device = xm.xla_device()\n",
        "# torch.set_default_tensor_type('torch.FloatTensor')\n",
        "\n",
        "## GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "## Weight and biases\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jRIVkpdv7iM"
      },
      "source": [
        "# Global variables "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-18T11:58:11.225720Z",
          "iopub.status.busy": "2022-04-18T11:58:11.225349Z",
          "iopub.status.idle": "2022-04-18T11:58:11.234233Z",
          "shell.execute_reply": "2022-04-18T11:58:11.233215Z",
          "shell.execute_reply.started": "2022-04-18T11:58:11.225677Z"
        },
        "id": "huwjGSaZv7iN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "INPUT_SIZE = 400\n",
        "N_CLASS = 4\n",
        "WHERE = \"home\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "e-dNYYCyz8E4"
      },
      "outputs": [],
      "source": [
        "if WHERE==\"colab\":\n",
        "\tPATH_LABELS = \"/content/index_label_bbox.csv\"\n",
        "\tPATH_IMG = \"/content/output/output\"\n",
        "\tPATH_LABELS_VALID = \"/content/index_label_bbox_validation.csv\"\n",
        "\tPATH_IMG_VALID = \"/content/output_validation/output_validation\"\n",
        "\tBATCH_SIZE = 64\n",
        "elif WHERE==\"kaggle\":\n",
        "\tPATH_LABELS = \"../input/boudingboxonlyhanddataset/index_label_bbox.csv\"\n",
        "\tPATH_IMG = \"../input/boudingboxonlyhanddataset/output/output\"\n",
        "\tPATH_LABELS_VALID = \"../input/boudingboxonlyhanddataset/index_label_bbox_validation.csv\"\n",
        "\tPATH_IMG_VALID = \"../input/boudingboxonlyhanddataset/output_validation/output_validation\"\n",
        "\tBATCH_SIZE = 64\n",
        "elif WHERE==\"home\":\n",
        "\tPATH_LABELS = \"../../../data_labels/bounding_box_model/done/index_label_bbox.csv\"\n",
        "\tPATH_IMG = \"../../../data_labels/bounding_box_model/done/output\"\n",
        "\tPATH_LABELS_VALID = \"../../../data_labels/bounding_box_model/done_validation/index_label_bbox_validation.csv\"\n",
        "\tPATH_IMG_VALID = \"../../../data_labels/bounding_box_model/done_validation/output_validation\"\n",
        "\tBATCH_SIZE = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-11T16:20:53.566375Z",
          "iopub.status.busy": "2022-04-11T16:20:53.56609Z",
          "iopub.status.idle": "2022-04-11T16:20:53.569977Z",
          "shell.execute_reply": "2022-04-11T16:20:53.569332Z",
          "shell.execute_reply.started": "2022-04-11T16:20:53.566327Z"
        },
        "id": "nSGukie2v7iN"
      },
      "source": [
        "# Data functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-18T11:58:11.236305Z",
          "iopub.status.busy": "2022-04-18T11:58:11.236071Z",
          "iopub.status.idle": "2022-04-18T11:58:11.248085Z",
          "shell.execute_reply": "2022-04-18T11:58:11.247309Z",
          "shell.execute_reply.started": "2022-04-18T11:58:11.236276Z"
        },
        "id": "uwmn_pJKv7iO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class HandGestureDataset(Dataset):\n",
        "\tdef __init__(self, annotations_file, img_dir, transform=None):\n",
        "\t\tself.img_labels = pd.read_csv(annotations_file)\n",
        "\t\tself.img_dir = img_dir\n",
        "\t\tself.transform = transform\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.img_labels)\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\timg_path = os.path.join(self.img_dir, os.listdir(self.img_dir)[idx])\n",
        "\t\timage = read_image(img_path)\n",
        "\t\t# image = image/INPUT_SIZE\n",
        "\t\tpath = str(\"output/\"+os.listdir(self.img_dir)[idx]).split(\"/\")[0]\n",
        "\t\tline = self.img_labels[\"index\"] == str(path+\"/\"+os.listdir(self.img_dir)[idx])\n",
        "\t\tx, y, x_end, y_end = self.img_labels.loc[line][\"x\"].item(),\\\n",
        "\t\t\t\t\t\t\t\tself.img_labels.loc[line][\"y\"].item(),\\\n",
        "\t\t\t\t\t\t\t\tself.img_labels.loc[line][\"x_end\"].item(),\\\n",
        "\t\t\t\t\t\t\t\tself.img_labels.loc[line][\"y_end\"].item()\n",
        "\t\t# x, y, x_end, y_end = x/INPUT_SIZE, y/INPUT_SIZE, x_end/INPUT_SIZE, y_end/INPUT_SIZE\n",
        "\t\timage = image.permute(1,2,0)\n",
        "\t\t# image = image/INPUT_SIZE\n",
        "\t\t# print(\"beforetransfo\", x, y, x_end, y_end)\n",
        "\t\tif self.transform:\n",
        "\t\t\ttransformed = self.transform(image=np.array(image), bboxes=[[x,y,x_end,y_end]])\n",
        "\t\ttransformed_image = transformed['image']\n",
        "\t\ttransformed_bboxes = transformed['bboxes']\n",
        "\t\t# print(transformed_image)\n",
        "\t\t# print(transformed_bboxes)\n",
        "\t\t# return {'image':image, 'x':x, 'y':y, 'x_end':x_end, 'y_end':y_end}\n",
        "\t\t# return {'image':image, 'bboxes':[x,y,x_end,y_end]}\n",
        "\t\t# print(\"transfo\",transformed_bboxes)\n",
        "\t\treturn transformed_image, transformed_bboxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-18T11:58:11.250531Z",
          "iopub.status.busy": "2022-04-18T11:58:11.250098Z",
          "iopub.status.idle": "2022-04-18T11:58:11.263487Z",
          "shell.execute_reply": "2022-04-18T11:58:11.262296Z",
          "shell.execute_reply.started": "2022-04-18T11:58:11.250483Z"
        },
        "id": "VQreQL2ov7iP",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def draw_predictions(image, preds):\n",
        "\tstartX, startY, endX, endY = preds\n",
        "\t# scale the predicted bounding box coordinates based on the image\n",
        "\t# dimensions    \n",
        "\tstartX = int(startX * INPUT_SIZE)\n",
        "\tstartY = int(startY * INPUT_SIZE)\n",
        "\tendX = int(endX * INPUT_SIZE)\n",
        "\tendY = int(endY * INPUT_SIZE)\n",
        "\t#     print(startX, startY, endX, endY)\n",
        "\t# draw the predicted bounding box on the image\n",
        "\timage = image.numpy().copy()\n",
        "\tcv2.rectangle(image, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
        "\t# show the output image\n",
        "\tplt.imshow(image)\n",
        "\tplt.show()\n",
        "\n",
        "def prepare_data_vgg(data_type):\n",
        "    ## Parameters fitting vgg/imagenet\n",
        "\tmean=[0.485, 0.456, 0.406]\n",
        "\tstd=[0.229, 0.224, 0.225]\n",
        "\n",
        "\ttransformVGGTrainAlbu = A.Compose([\n",
        "\t\t# A.RandomCrop(width=400, height=400),\n",
        "\t\t# A.HorizontalFlip(p=0.5),\n",
        "\t\tA.RandomBrightnessContrast(p=0.5),\n",
        "\t], bbox_params=A.BboxParams(format='pascal_voc', label_fields=\"\"))\n",
        "\n",
        "\t## pytorch transformer objects\n",
        "\ttransformVGGTrain=transforms.Compose([\n",
        "\t\t\ttransforms.ToPILImage(),\n",
        "\t\t\t## can try\n",
        "\t\t\t# transforms.ColorJitter(brightness=0.5, hue=0.5),\n",
        "\t\t\t# transforms.RandomAdjustSharpness(sharpness_factor=3),\n",
        "\t\t\t# transforms.RandomAutocontrast(),\n",
        "\t\t\t# transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.01, 5)),\n",
        "\t\t\t## don't use or it will ruin bounding box labels\n",
        "\t#             transforms.RandomRotation(degrees=(-15, 15)),\n",
        "\t#             transforms.RandomPerspective(distortion_scale=0.4, p=0.2),\n",
        "\t#             transforms.RandomAffine(degrees=(0, 5), translate=(0, 0.18), scale=(0.7, 1)),\n",
        "\t\t\t## too much\n",
        "\t\t\t# transforms.RandomSolarize(threshold=192.0),\n",
        "\t#             transforms.RandomPosterize(bits=2),\n",
        "\t#             transforms.RandomInvert(),\n",
        "\t#             transforms.RandomEqualize(),\n",
        "\t\t\ttransforms.Resize(size=(INPUT_SIZE, INPUT_SIZE)),\n",
        "\t\t\ttransforms.ToTensor(),\n",
        "\t#             transforms.Normalize(mean, std) ## test with and without\n",
        "        ])\n",
        "\ttransformVGGValid=transforms.Compose([\n",
        "\t\t\ttransforms.ToPILImage(),\n",
        "\t\t\ttransforms.Resize(size=(INPUT_SIZE, INPUT_SIZE)),\n",
        "\t\t\ttransforms.ToTensor(),\n",
        "\t#             transforms.Normalize(mean, std) ## test with and without\n",
        "\t\t])\n",
        "\n",
        "\tif data_type == \"custom\":\n",
        "\t\t## Custom dataset\n",
        "\t\tVGG_dataset_train = HandGestureDataset(PATH_LABELS, PATH_IMG, transformVGGTrainAlbu)\n",
        "\t\tVGG_dataset_valid = HandGestureDataset(PATH_LABELS_VALID, PATH_IMG_VALID, transformVGGValid)\n",
        "\t\tVGG_trainloader = torch.utils.data.DataLoader(VGG_dataset_train, batch_size=BATCH_SIZE, pin_memory=True, shuffle=True)\n",
        "\t\tVGG_validloader = torch.utils.data.DataLoader(VGG_dataset_valid, batch_size=BATCH_SIZE, pin_memory=True, shuffle=True)\n",
        "\n",
        "\treturn VGG_trainloader, VGG_validloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-15T15:49:41.695334Z",
          "iopub.status.busy": "2022-02-15T15:49:41.69497Z",
          "iopub.status.idle": "2022-02-15T15:49:46.639507Z",
          "shell.execute_reply": "2022-02-15T15:49:46.638679Z",
          "shell.execute_reply.started": "2022-02-15T15:49:41.695293Z"
        },
        "id": "I7EYl1LCv7iQ"
      },
      "source": [
        "# Loading data into pytorch dataset and dataloader objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-18T11:58:11.265540Z",
          "iopub.status.busy": "2022-04-18T11:58:11.265294Z",
          "iopub.status.idle": "2022-04-18T11:58:11.301628Z",
          "shell.execute_reply": "2022-04-18T11:58:11.300387Z",
          "shell.execute_reply.started": "2022-04-18T11:58:11.265514Z"
        },
        "id": "gSLUtb3rv7iQ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "VGG_trainloader, VGG_validloader = prepare_data_vgg(\"custom\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-18T11:58:11.303751Z",
          "iopub.status.busy": "2022-04-18T11:58:11.303355Z",
          "iopub.status.idle": "2022-04-18T11:58:11.309138Z",
          "shell.execute_reply": "2022-04-18T11:58:11.308066Z",
          "shell.execute_reply.started": "2022-04-18T11:58:11.303704Z"
        },
        "id": "Dxv-Unzwv7iR",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([400, 400, 3])\n",
            "[tensor([ 17.,  76., 170., 119.], dtype=torch.float64)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\karna\\AppData\\Local\\Temp\\ipykernel_22644\\500527189.py:5: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  res.append(np.array(e))\n",
            "C:\\Users\\karna\\AppData\\Local\\Temp\\ipykernel_22644\\500527189.py:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  res.append(np.array(e))\n"
          ]
        }
      ],
      "source": [
        "for batch in VGG_trainloader:\n",
        "\timg, bbox = batch\n",
        "\tres = []\n",
        "\tfor e in bbox:\n",
        "\t\tres.append(np.array(e))\n",
        "\tres = np.array(res).T\n",
        "\tfor i, l in zip(img, res):\n",
        "\t\tprint(i.shape)\n",
        "\t\tprint(l)\n",
        "\t\tbreak\n",
        "\tbreak\n",
        "\t\t# draw_predictions(i, l.item())\n",
        "\t# \tbreak\n",
        "\t# break\n",
        "\t# \tbreak\n",
        "\t# break\n",
        "\n",
        "# def show_img(img):\n",
        "#     plt.figure(figsize=(18,15))\n",
        "#     # unnormalize\n",
        "#     img = img / 2 + 0.5  \n",
        "#     npimg = img.numpy()\n",
        "#     npimg = np.clip(npimg, 0., 1.)\n",
        "#     plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "#     plt.show()\n",
        "# data = iter(VGG_trainloader)\n",
        "# images = data.next()\n",
        "# show_img(torchvision.utils.make_grid(images))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yNIY1tPv7iR"
      },
      "source": [
        "# Model functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2022-04-18T11:58:11.311833Z",
          "iopub.status.busy": "2022-04-18T11:58:11.311177Z",
          "iopub.status.idle": "2022-04-18T11:58:11.337631Z",
          "shell.execute_reply": "2022-04-18T11:58:11.336657Z",
          "shell.execute_reply.started": "2022-04-18T11:58:11.311779Z"
        },
        "id": "TmOsJNGTv7iS",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train(model, epochs, train_loader, valid_loader, learning_rate, patience, feature_extract=False):\n",
        "\t## Early stopping variables\n",
        "\tes = EarlyStopping(patience=patience)\n",
        "\tterminate_training = False\n",
        "\tbest_model_wts = copy.deepcopy(model.state_dict())\n",
        "\tbest_loss = np.inf\n",
        "\tmodel = model.to(device)\n",
        "\t## Training only the parameters where we require gradient since we are fine-tuning\n",
        "\tparams_to_update = model.parameters()\n",
        "\tprint(\"params to learn:\")\n",
        "\tif feature_extract:\n",
        "\t\tparams_to_update = []\n",
        "\t\tfor name,param in model.named_parameters():\n",
        "\t\t\tif param.requires_grad == True:\n",
        "\t\t\t\tparams_to_update.append(param)\n",
        "\t\t\t\tprint(\"\\t\", name)\n",
        "\telse:\n",
        "\t\tfor name,param in model.named_parameters():\n",
        "\t\t\tif param.requires_grad == True:\n",
        "\t\t\t\tprint(\"\\t\", name)\n",
        "                \n",
        "\t## Setting up our optimizer\n",
        "\toptim = torch.optim.Adam(params_to_update, lr=learning_rate)\n",
        "\n",
        "\t## Setting up our loss function\n",
        "\tloss = nn.MSELoss()\n",
        "    \n",
        "\t## Running the train loop\n",
        "\tprint(f\"running {model.name}\")\n",
        "\tfor epoch in range(epochs):\n",
        "\t\tcumloss, count = 0, 0\n",
        "\t\tmodel.train()\n",
        "\t\tfor item in train_loader:\n",
        "\t\t\toptim.zero_grad()\n",
        "\t\t\tx, y = item[\"image\"], item[\"label\"]\n",
        "\t\t\tx = item[\"image\"].to(device)\n",
        "\t\t\t\n",
        "\t\t\tres = []\n",
        "\t\t\tfor e in y:\n",
        "\t\t\t\tres.append(np.array(e))\n",
        "\t\t\tres = np.array(res).T\n",
        "\t\t\ty = torch.as_tensor(res)\n",
        "\t\t\ty = y.to(torch.float32)\n",
        "\t\t\ty = y.to(device)\n",
        "\t\t\t\n",
        "\t\t\tyhat = model(x)\n",
        "\n",
        "\t\t\tl = loss(yhat, y)\n",
        "\t\t\tl.backward()\n",
        "\t\t\t# xm.optimizer_step(optim, barrier=True)\n",
        "\t\t\toptim.step()\n",
        "\t\t\tcumloss += l * len(x)\n",
        "\t\t\tcount += len(x)\n",
        "\t\tprint(\"epoch :\", epoch, end=\"\")\n",
        "\t\tloss_ = cumloss.cpu().item()/count\n",
        "\t\twandb.log({'train_loss': loss_})\n",
        "\t\tprint(\", train_loss: \", loss_, end=\"\")\n",
        "\t\tif epoch % 1 == 0:\n",
        "\t\t\tmodel.eval()\n",
        "\t\t\twith torch.no_grad():\n",
        "\t\t\t\tvalid_cumloss, count = 0, 0\n",
        "\t\t\t\tfor x,y in valid_loader:\n",
        "\t\t\t\t\tx, y = item[\"image\"], item[\"label\"]\n",
        "\t\t\t\t\tx = item[\"image\"].to(device)\n",
        "\t\t\t\t\tres = []\n",
        "\t\t\t\t\tfor e in y:\n",
        "\t\t\t\t\t\tres.append(np.array(e))\n",
        "\t\t\t\t\tres = np.array(res).T\n",
        "\t\t\t\t\ty = torch.as_tensor(res)\n",
        "\t\t\t\t\ty = y.to(torch.float32)\n",
        "\t\t\t\t\ty = y.to(device)\n",
        "\t\t\t\t\tyhat = model(x)\n",
        "\t\t\t\t\tvalid_cumloss += loss(yhat,y) * len(x)\n",
        "\t\t\t\t\tcount += len(x)\n",
        "\t\t\t\tvalid_loss_ = valid_cumloss.cpu().item()/count\n",
        "\t\t\t\twandb.log({'valid_loss': valid_loss_})\n",
        "\t\t\t\tprint(\", valid_loss: \", valid_loss_)\n",
        "\t\t\t\t## Early stopping\n",
        "\t\t\t\tif valid_cumloss/count < best_loss:\n",
        "\t\t\t\t\tbest_loss = valid_cumloss/count\n",
        "\t\t\t\t\tbest_model_wts = copy.deepcopy(model.state_dict())\n",
        "\t\t\t\tif es.step(valid_cumloss.cpu().item()/count):\n",
        "\t\t\t\t\tterminate_training = True\n",
        "\t\t\t\t\tbreak\n",
        "\t\tif terminate_training:\n",
        "\t\t\tbreak\n",
        "\tprint('Best val loss: {:4f}'.format(best_loss))\n",
        "\t## Returns the best model\n",
        "\tmodel.load_state_dict(best_model_wts)\n",
        "\treturn model\n",
        "\n",
        "def set_parameter_requires_grad(model, feature_extract):\n",
        "\tif feature_extract:\n",
        "\t\tfor name,p in model.named_parameters():\n",
        "\t\t\tif \"features\" in name:\n",
        "\t\t\t\tp.requires_grad = False    \n",
        "\t\t\telse:\n",
        "\t\t\t\tp.requires_grad = True  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-11T16:22:20.614896Z",
          "iopub.status.busy": "2022-04-11T16:22:20.614632Z",
          "iopub.status.idle": "2022-04-11T16:22:20.618197Z",
          "shell.execute_reply": "2022-04-11T16:22:20.617386Z",
          "shell.execute_reply.started": "2022-04-11T16:22:20.614868Z"
        },
        "id": "LdrT-bVhv7iS"
      },
      "source": [
        "# Loading the model and modifying the classifier part\n",
        "### Maybe we could try to modify only the last classifier layer ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-04-18T11:58:11.339763Z",
          "iopub.status.busy": "2022-04-18T11:58:11.339400Z",
          "iopub.status.idle": "2022-04-18T11:58:25.947622Z",
          "shell.execute_reply": "2022-04-18T11:58:25.946904Z",
          "shell.execute_reply.started": "2022-04-18T11:58:11.339717Z"
        },
        "id": "X_bEUNDLv7iT",
        "outputId": "979d2b9c-aeb1-4d0f-cb42-5f695f0d8892",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=1024, out_features=256, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=256, out_features=4, bias=True)\n",
            "    (7): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "## Loading vgg16 model pretrained on imagenet\n",
        "vgg = models.vgg16(pretrained=True)\n",
        "\n",
        "vgg.classifier = nn.Sequential(nn.Linear(25088, 4096), \n",
        "                               nn.ReLU(), \n",
        "                              #  nn.Dropout(0.5),        \n",
        "                               nn.Linear(4096, 1024), \n",
        "                               nn.ReLU(), \n",
        "#                                nn.Dropout(0.5),        \n",
        "                               nn.Linear(1024, 256),\n",
        "                               nn.ReLU(), \n",
        "#                                nn.Dropout(0.5),        \n",
        "                               nn.Linear(256, N_CLASS),\n",
        "                               nn.Sigmoid())\n",
        "\n",
        "print(vgg.eval())\n",
        "\n",
        "## Sets all the requires grad of the classifier layers to True\n",
        "set_parameter_requires_grad(vgg, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiqed-DRv7iT"
      },
      "source": [
        "# Implementing early stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-18T11:58:25.949868Z",
          "iopub.status.busy": "2022-04-18T11:58:25.949095Z",
          "iopub.status.idle": "2022-04-18T11:58:25.963637Z",
          "shell.execute_reply": "2022-04-18T11:58:25.962806Z",
          "shell.execute_reply.started": "2022-04-18T11:58:25.949814Z"
        },
        "id": "N4pImz6Av7iU",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class EarlyStopping(object):\n",
        "    def __init__(self, mode='min', min_delta=0, patience=10, percentage=False):\n",
        "        self.mode = mode\n",
        "        self.min_delta = min_delta\n",
        "        self.patience = patience\n",
        "        self.best = None\n",
        "        self.num_bad_epochs = 0\n",
        "        self.is_better = None\n",
        "        self._init_is_better(mode, min_delta, percentage)\n",
        "        if patience == 0:\n",
        "            self.is_better = lambda a, b: True\n",
        "            self.step = lambda a: False\n",
        "\n",
        "    def step(self, metrics):\n",
        "        if self.best is None:\n",
        "            self.best = metrics\n",
        "            return False\n",
        "        if np.isnan(metrics):\n",
        "            return True\n",
        "        if self.is_better(metrics, self.best):\n",
        "            self.num_bad_epochs = 0\n",
        "            self.best = metrics\n",
        "        else:\n",
        "            self.num_bad_epochs += 1\n",
        "        if self.num_bad_epochs >= self.patience:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def _init_is_better(self, mode, min_delta, percentage):\n",
        "        if mode not in {'min', 'max'}:\n",
        "            raise ValueError('mode ' + mode + ' is unknown!')\n",
        "        if not percentage:\n",
        "            if mode == 'min':\n",
        "                self.is_better = lambda a, best: a < best - min_delta\n",
        "            if mode == 'max':\n",
        "                self.is_better = lambda a, best: a > best + min_delta\n",
        "        else:\n",
        "            if mode == 'min':\n",
        "                self.is_better = lambda a, best: a < best - (\n",
        "                            best * min_delta / 100)\n",
        "            if mode == 'max':\n",
        "                self.is_better = lambda a, best: a > best + (\n",
        "                            best * min_delta / 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRpWlPvEv7iU"
      },
      "source": [
        "# Training only the modified parts of the classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "os.environ['WANDB_NOTEBOOK_NAME'] = '4096_5e-6'\n",
        "wandb.init(project=\"jetson-autonomous-driving\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-04-18T11:58:25.966171Z",
          "iopub.status.busy": "2022-04-18T11:58:25.965782Z",
          "iopub.status.idle": "2022-04-18T12:39:06.745835Z",
          "shell.execute_reply": "2022-04-18T12:39:06.743472Z",
          "shell.execute_reply.started": "2022-04-18T11:58:25.966134Z"
        },
        "id": "JXlDQQfhv7iV",
        "outputId": "104d8c3c-b1f4-4f4c-80f2-98fed954fe48",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "536\n",
            "151\n",
            "params to learn:\n",
            "\t classifier.0.weight\n",
            "\t classifier.0.bias\n",
            "\t classifier.2.weight\n",
            "\t classifier.2.bias\n",
            "\t classifier.4.weight\n",
            "\t classifier.4.bias\n",
            "\t classifier.6.weight\n",
            "\t classifier.6.bias\n",
            "running VGG\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Input type (torch.cuda.ByteTensor) and weight type (torch.cuda.FloatTensor) should be the same",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\karna\\Desktop\\Projects\\PythonProject\\JetsonAutonomousDriving\\src\\main\\only_bounding_box_model\\vgg_bounding_box.ipynb Cell 23'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karna/Desktop/Projects/PythonProject/JetsonAutonomousDriving/src/main/only_bounding_box_model/vgg_bounding_box.ipynb#ch0000022?line=3'>4</a>\u001b[0m \u001b[39m## Fine-tuning the model on our data\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karna/Desktop/Projects/PythonProject/JetsonAutonomousDriving/src/main/only_bounding_box_model/vgg_bounding_box.ipynb#ch0000022?line=4'>5</a>\u001b[0m vgg\u001b[39m.\u001b[39mname \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mVGG\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/karna/Desktop/Projects/PythonProject/JetsonAutonomousDriving/src/main/only_bounding_box_model/vgg_bounding_box.ipynb#ch0000022?line=6'>7</a>\u001b[0m best_model \u001b[39m=\u001b[39m train(model\u001b[39m=\u001b[39;49mvgg, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karna/Desktop/Projects/PythonProject/JetsonAutonomousDriving/src/main/only_bounding_box_model/vgg_bounding_box.ipynb#ch0000022?line=7'>8</a>\u001b[0m                    epochs\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karna/Desktop/Projects/PythonProject/JetsonAutonomousDriving/src/main/only_bounding_box_model/vgg_bounding_box.ipynb#ch0000022?line=8'>9</a>\u001b[0m                    train_loader\u001b[39m=\u001b[39;49mVGG_trainloader, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/karna/Desktop/Projects/PythonProject/JetsonAutonomousDriving/src/main/only_bounding_box_model/vgg_bounding_box.ipynb#ch0000022?line=9'>10</a>\u001b[0m                    valid_loader\u001b[39m=\u001b[39;49mVGG_validloader, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/karna/Desktop/Projects/PythonProject/JetsonAutonomousDriving/src/main/only_bounding_box_model/vgg_bounding_box.ipynb#ch0000022?line=10'>11</a>\u001b[0m                    learning_rate\u001b[39m=\u001b[39;49m\u001b[39m5e-6\u001b[39;49m, \u001b[39m## 3e-4 learning rate for Adam optimizer\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/karna/Desktop/Projects/PythonProject/JetsonAutonomousDriving/src/main/only_bounding_box_model/vgg_bounding_box.ipynb#ch0000022?line=11'>12</a>\u001b[0m                    patience\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n",
            "\u001b[1;32mc:\\Users\\karna\\Desktop\\Projects\\PythonProject\\JetsonAutonomousDriving\\src\\main\\only_bounding_box_model\\vgg_bounding_box.ipynb Cell 16'\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, epochs, train_loader, valid_loader, learning_rate, patience, feature_extract)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/karna/Desktop/Projects/PythonProject/JetsonAutonomousDriving/src/main/only_bounding_box_model/vgg_bounding_box.ipynb#ch0000015?line=42'>43</a>\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/karna/Desktop/Projects/PythonProject/JetsonAutonomousDriving/src/main/only_bounding_box_model/vgg_bounding_box.ipynb#ch0000015?line=43'>44</a>\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/karna/Desktop/Projects/PythonProject/JetsonAutonomousDriving/src/main/only_bounding_box_model/vgg_bounding_box.ipynb#ch0000015?line=45'>46</a>\u001b[0m yhat \u001b[39m=\u001b[39m model(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/karna/Desktop/Projects/PythonProject/JetsonAutonomousDriving/src/main/only_bounding_box_model/vgg_bounding_box.ipynb#ch0000015?line=47'>48</a>\u001b[0m l \u001b[39m=\u001b[39m loss(yhat, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/karna/Desktop/Projects/PythonProject/JetsonAutonomousDriving/src/main/only_bounding_box_model/vgg_bounding_box.ipynb#ch0000015?line=48'>49</a>\u001b[0m l\u001b[39m.\u001b[39mbackward()\n",
            "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torchvision\\models\\vgg.py:66\u001b[0m, in \u001b[0;36mVGG.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torchvision/models/vgg.py?line=64'>65</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m---> <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torchvision/models/vgg.py?line=65'>66</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures(x)\n\u001b[0;32m     <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torchvision/models/vgg.py?line=66'>67</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)\n\u001b[0;32m     <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torchvision/models/vgg.py?line=67'>68</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m)\n",
            "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
            "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\nn\\modules\\conv.py:447\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/conv.py?line=445'>446</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/conv.py?line=446'>447</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\nn\\modules\\conv.py:443\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/conv.py?line=438'>439</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/conv.py?line=439'>440</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/conv.py?line=440'>441</a>\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/conv.py?line=441'>442</a>\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/conv.py?line=442'>443</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/conv.py?line=443'>444</a>\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.cuda.ByteTensor) and weight type (torch.cuda.FloatTensor) should be the same"
          ]
        }
      ],
      "source": [
        "print(len(VGG_trainloader))\n",
        "print(len(VGG_validloader))\n",
        "\n",
        "## Fine-tuning the model on our data\n",
        "vgg.name = \"VGG\"\n",
        "\n",
        "best_model = train(model=vgg, \n",
        "                   epochs=1000, \n",
        "                   train_loader=VGG_trainloader, \n",
        "                   valid_loader=VGG_validloader, \n",
        "                   learning_rate=5e-6, ## 3e-4 learning rate for Adam optimizer\n",
        "                   patience=20) ## metric for earlystopping : val_loss "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_RQMAV0v7iV"
      },
      "source": [
        "# Checking predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T12:39:06.750237Z",
          "iopub.status.idle": "2022-04-18T12:39:06.750629Z",
          "shell.execute_reply": "2022-04-18T12:39:06.750455Z",
          "shell.execute_reply.started": "2022-04-18T12:39:06.750430Z"
        },
        "id": "FDqVuSEIv7iW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# with torch.no_grad():\n",
        "#     for item in VGG_validloader:\n",
        "#         x, y = item[\"image\"], item[\"label\"]\n",
        "#         base_img = item[\"image\"]\n",
        "#         x = item[\"image\"].to(device)\n",
        "#         res = []\n",
        "#         for e in y:\n",
        "#             res.append(np.array(e))\n",
        "#         res = np.array(res).T\n",
        "#         y = torch.as_tensor(res)\n",
        "#         y = y.to(torch.float32)\n",
        "#         y = y.to(device)\n",
        "#         yhat = best_model(x)\n",
        "#         for i in range(4):\n",
        "#             draw_predictions(base_img[i].permute(1,2,0), yhat.cpu()[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOuDvy_7v7iW"
      },
      "source": [
        "# Saving the model in .pth and .onnx extension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T12:39:06.752154Z",
          "iopub.status.idle": "2022-04-18T12:39:06.752540Z",
          "shell.execute_reply": "2022-04-18T12:39:06.752374Z",
          "shell.execute_reply.started": "2022-04-18T12:39:06.752351Z"
        },
        "id": "69YZ-O8Pv7iW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "PATH = \"./\"\n",
        "torch.save(best_model.state_dict(), os.path.join(PATH,\"boundingbox_vgg_last.pth\"))\n",
        "# from google.colab import files\n",
        "# files.download(os.path.join(PATH,\"boundingbox_vgg_last.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T12:39:06.753863Z",
          "iopub.status.idle": "2022-04-18T12:39:06.754276Z",
          "shell.execute_reply": "2022-04-18T12:39:06.754087Z",
          "shell.execute_reply.started": "2022-04-18T12:39:06.754066Z"
        },
        "id": "k3zZ0xCAv7iX",
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.9.12 64-bit (windows store)' requires ipykernel package.\n",
            "Run the following command to install 'ipykernel' into the Python environment. \n",
            "Command: 'C:/Users/karna/AppData/Local/Microsoft/WindowsApps/python3.9.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# del vgg\n",
        "# del best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T12:39:06.755923Z",
          "iopub.status.idle": "2022-04-18T12:39:06.756323Z",
          "shell.execute_reply": "2022-04-18T12:39:06.756152Z",
          "shell.execute_reply.started": "2022-04-18T12:39:06.756129Z"
        },
        "id": "fhRGHT_zv7iX",
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.9.12 64-bit (windows store)' requires ipykernel package.\n",
            "Run the following command to install 'ipykernel' into the Python environment. \n",
            "Command: 'C:/Users/karna/AppData/Local/Microsoft/WindowsApps/python3.9.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# model = models.vgg16(pretrained=True)\n",
        "# model.classifier[0] = nn.Linear(25088, 8192)\n",
        "# model.classifier[3] = nn.Linear(8192, 1024)\n",
        "# model.classifier[6] = nn.Linear(1024, N_CLASS)\n",
        "# model.load_state_dict(torch.load(os.path.join(PATH,\"vgg.pth\"), map_location='cpu'))\n",
        "# model.eval() \n",
        "\n",
        "# dummy_input = torch.randn(BATCH_SIZE, 3, INPUT_SIZE, INPUT_SIZE)  \n",
        "# torch.onnx.export(model,   \n",
        "#                   dummy_input, \n",
        "#                   \"vgg.onnx\",\n",
        "#                   export_params=True,\n",
        "#                   do_constant_folding=True, \n",
        "#                   input_names = ['modelInput'],\n",
        "#                   output_names = ['modelOutput'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nyDFGuUv7iX"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.9.12 64-bit (windows store)' requires ipykernel package.\n",
            "Run the following command to install 'ipykernel' into the Python environment. \n",
            "Command: 'C:/Users/karna/AppData/Local/Microsoft/WindowsApps/python3.9.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLpVF-Vov7iX"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.9.12 64-bit (windows store)' requires ipykernel package.\n",
            "Run the following command to install 'ipykernel' into the Python environment. \n",
            "Command: 'C:/Users/karna/AppData/Local/Microsoft/WindowsApps/python3.9.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "vgg_bounding_box.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
