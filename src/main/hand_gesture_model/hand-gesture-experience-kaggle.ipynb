{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"# %matplotlib inline\n\nimport time\nimport os\nimport cv2\nimport random\nimport imageio\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport pandas as pd\n\nfrom tqdm import tqdm\nfrom io import BytesIO\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\n## BUG MEMORY, REFAIRE LA DATA AUGMENTATION SANS TUER LA MEMOIRE !!!","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:12:37.695195Z","iopub.execute_input":"2022-04-04T19:12:37.695711Z","iopub.status.idle":"2022-04-04T19:12:45.352597Z","shell.execute_reply.started":"2022-04-04T19:12:37.695616Z","shell.execute_reply":"2022-04-04T19:12:45.351742Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Global variables","metadata":{}},{"cell_type":"code","source":"LABELS = ['FINGER', 'FIST', 'LEFT', 'PALM', 'RIGHT', 'EMPTY']\nN_LABELS = len(LABELS)\nINPUT_SIZE = 128 # width and height\nOS = \"linux\"\nTPU = True\nVALID_SIZE = 0.2\nVIDEO_PATH = \"../input/hand-gesture/data_background/test.mkv\" ## On kaggle\n# VIDEO_PATH = \"data_background/test.mkv\" ## On computer\n# label_name = [\"palm_horizontal\", \"L\", \"fist_horizontal\", \"fist_vertical\", \"thumb_up\", \"index\", \"ok\", \"palm_vertical\", \"C\", \"thumb_down\"]","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:12:45.354044Z","iopub.execute_input":"2022-04-04T19:12:45.354692Z","iopub.status.idle":"2022-04-04T19:12:45.359598Z","shell.execute_reply.started":"2022-04-04T19:12:45.354658Z","shell.execute_reply":"2022-04-04T19:12:45.358809Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"if TPU:\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Device:', tpu.master())\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    except:\n        strategy = tf.distribute.get_strategy()\n    print('Number of replicas:', strategy.num_replicas_in_sync)\n\n    AUTOTUNE = tf.data.experimental.AUTOTUNE\n    BATCH_SIZE = 16 * strategy.num_replicas_in_sync\nelse:\n    BATCH_SIZE = 128","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:12:45.360728Z","iopub.execute_input":"2022-04-04T19:12:45.361076Z","iopub.status.idle":"2022-04-04T19:12:51.048464Z","shell.execute_reply.started":"2022-04-04T19:12:45.361049Z","shell.execute_reply":"2022-04-04T19:12:51.047452Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Loading data","metadata":{}},{"cell_type":"code","source":"def load_labelling_data():\n    X = []\n    y = []\n    if OS == \"windows\":\n        split_ = \"\\\\\"\n    else:\n        split_ = \"/\"\n    for root, _, files in tqdm(os.walk(\"../\", topdown=False)): \n        for name in files:\n            path = os.path.join(root, name)\n            if path.endswith(\"jpg\"):\n                # if path.split(split_)[-1][0] != \".\":\n                if path.split(split_)[-1][0].isalpha():\n                    # Loading images\n                    img = cv2.imread(path)\n                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n                    X.append(img)\n                    # Loading labels\n                    category = path.split(split_)[-1].split(\"_\")[0]\n                    # label = int(category.split(\"_\")[0]) - 1\n                    y.append(category)\n    X = np.array(X)\n    y = np.array(y)\n    return X[:,:,:,np.newaxis], y\n\ndef load_test_data(width, height):\n    X = []\n    if OS == \"windows\":\n        split_ = \"\\\\\"\n    else:\n        split_ = \"/\"\n    for root, _, files in tqdm(os.walk(\"../\", topdown=False)): \n        for name in files:\n            path = os.path.join(root, name)\n            if path.endswith(\"jpg\"):\n                # if path.split(split_)[-1][0] != \".\":\n                if not path.split(split_)[-1][0].isalpha() and path.split(split_)[-1][0] != \".\":\n                    # Loading images\n                    img = cv2.imread(path)\n                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n                    img = cv2.resize(img, (width, height))\n                    X.append(img)\n    X = np.array(X)\n    return X.reshape(X.shape[0], height, width, 1)\n\ndef get_background_images():\n    images = []\n    vidcap = cv2.VideoCapture(VIDEO_PATH)\n    success,image = vidcap.read()\n    while success:\n        img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)[:,:,np.newaxis]\n        images.append(img)\n        success, image = vidcap.read()\n    return np.array(images)\n\n# def load_dataset_data(width, height):\n#     X = []\n#     y = []\n#     if OS == \"windows\":\n#         split_ = \"\\\\\"\n#     else:\n#         split_ = \"/\"\n#     for root, dirs, files in tqdm(os.walk(\".\", topdown=False)): \n#         for name in files:\n#             path = os.path.join(root, name)\n#             if path.endswith(\"png\"):\n#                 # Loading labels\n#                 category = path.split(split_)[4]\n#                 label = int(category.split(\"_\")[0]) - 1\n#                 y.append(label)\n#                 # Loading images\n#                 img = cv2.imread(path)\n#                 img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n#                 img = cv2.resize(img, (width, height))\n#                 X.append(img)\n#     X = np.array(X)\n#     y = np.array(y)\n#     return X.reshape(X.shape[0], height, width, 1), y","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:12:51.050405Z","iopub.execute_input":"2022-04-04T19:12:51.050648Z","iopub.status.idle":"2022-04-04T19:12:51.069159Z","shell.execute_reply.started":"2022-04-04T19:12:51.050611Z","shell.execute_reply":"2022-04-04T19:12:51.068007Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"X_labelling, y_labelling = load_labelling_data()\nbackground_img = get_background_images()\nbackground_images = background_img[::50]","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:12:51.070867Z","iopub.execute_input":"2022-04-04T19:12:51.071192Z","iopub.status.idle":"2022-04-04T19:12:56.521361Z","shell.execute_reply.started":"2022-04-04T19:12:51.071159Z","shell.execute_reply":"2022-04-04T19:12:56.520342Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(X_labelling.shape)\nprint(y_labelling.shape)\nprint(background_images.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:12:56.522759Z","iopub.execute_input":"2022-04-04T19:12:56.523715Z","iopub.status.idle":"2022-04-04T19:12:56.529850Z","shell.execute_reply.started":"2022-04-04T19:12:56.523677Z","shell.execute_reply":"2022-04-04T19:12:56.528883Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Data augmentation","metadata":{}},{"cell_type":"code","source":"plt.imshow(X_labelling[0])\nplt.show()\nplt.imshow(background_images[0])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:12:56.531677Z","iopub.execute_input":"2022-04-04T19:12:56.532265Z","iopub.status.idle":"2022-04-04T19:12:57.088070Z","shell.execute_reply.started":"2022-04-04T19:12:56.532230Z","shell.execute_reply":"2022-04-04T19:12:57.087037Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def fill(img, h, w):\n    img = cv2.resize(img, (h, w), cv2.INTER_CUBIC)\n    return img\n        \ndef horizontal_shift(img, ratio=0.0):\n    if ratio > 1 or ratio < 0:\n        return img\n    ratio = random.uniform(-ratio, ratio)\n    h, w = img.shape[:2]\n    to_shift = w*ratio\n    if ratio > 0:\n        img = img[:, :int(w-to_shift), :]\n    if ratio < 0:\n        img = img[:, int(-1*to_shift):, :]\n    img = fill(img, h, w)\n    return img\n\ndef vertical_shift(img, ratio=0.0):\n    if ratio > 1 or ratio < 0:\n        return img\n    ratio = random.uniform(-ratio, ratio)\n    h, w = img.shape[:2]\n    to_shift = h*ratio\n    if ratio > 0:\n        img = img[:int(h-to_shift), :, :]\n    if ratio < 0:\n        img = img[int(-1*to_shift):, :, :]\n    img = fill(img, h, w)\n    return img\n\ndef brightness(img, low, high):\n    value = random.uniform(low, high)\n    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n    hsv = np.array(hsv, dtype = np.float64)\n    hsv[:,:,1] = hsv[:,:,1]*value\n    hsv[:,:,1][hsv[:,:,1]>255]  = 255\n    hsv[:,:,2] = hsv[:,:,2]*value \n    hsv[:,:,2][hsv[:,:,2]>255]  = 255\n    hsv = np.array(hsv, dtype = np.uint8)\n    img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n    return img\n\ndef zoom(img, value):\n    if value > 1 or value < 0:\n        return img\n    value = random.uniform(value, 1)\n    h, w = img.shape[:2]\n    h_taken = int(value*h)\n    w_taken = int(value*w)\n    h_start = random.randint(0, h-h_taken)\n    w_start = random.randint(0, w-w_taken)\n    img = img[h_start:h_start+h_taken, w_start:w_start+w_taken, :]\n    img = fill(img, h, w)\n    return img\n\ndef channel_shift(img, value):\n    value = int(random.uniform(-value, value))\n    img = img + value\n    img[:,:,:][img[:,:,:]>255]  = 255\n    img[:,:,:][img[:,:,:]<0]  = 0\n    img = img.astype(np.uint8)\n    return img.squeeze()\n\ndef horizontal_flip(img, flag):\n    if flag:\n        return cv2.flip(img, 1)\n    else:\n        return img\n\ndef vertical_flip(img, flag):\n    if flag:\n        return cv2.flip(img, 0)\n    else:\n        return img\n\ndef rotation(img, angle):\n    angle = int(random.uniform(-angle, angle))\n    h, w = img.shape[:2]\n    M = cv2.getRotationMatrix2D((int(w/2), int(h/2)), angle, 1)\n    img = cv2.warpAffine(img, M, (w, h))\n    return img\n\ndef get_augmented_images(X, y):\n    X_augmented = []\n    y_augmented = []\n    for i in range(X.shape[0]):\n        X_augmented.append(X[i].squeeze())\n        y_augmented.append(y[i])\n        X_augmented.append(horizontal_shift(X[i], 0.7))\n        y_augmented.append(y[i])\n        X_augmented.append(vertical_shift(X[i], 0.7))\n        y_augmented.append(y[i])\n        # X_augmented.append(brightness(X[i], 0.5, 3))\n        # y_augmented.append(y[i])\n        X_augmented.append(zoom(X[i], 0.5))\n        y_augmented.append(y[i])\n        X_augmented.append(channel_shift(X[i], 60))\n        y_augmented.append(y[i])\n        # X_augmented.append(horizontal_flip(X[i], True))\n        # y_augmented.append(y[i])\n        # X_augmented.append(vertical_flip(X[i], True))\n        # y_augmented.append(y[i])\n        X_augmented.append(rotation(X[i], 20))\n        y_augmented.append(y[i])\n        X_augmented.append(rotation(X[i], 40))\n        y_augmented.append(y[i])\n        X_augmented.append(rotation(X[i], 60))\n        y_augmented.append(y[i])\n        X_augmented.append(rotation(X[i], -20))\n        y_augmented.append(y[i])\n        X_augmented.append(rotation(X[i], -40))\n        y_augmented.append(y[i])\n        X_augmented.append(rotation(X[i], -60))\n        y_augmented.append(y[i])\n    return np.array(X_augmented), np.array(y_augmented)\n\ndef get_augmented_background(X, n):\n    X_augmented = []\n    y_augmented = []\n    cpt = 0\n    for i in range(X.shape[0]):\n        if cpt == n:\n            break\n        X_augmented.append(X[i].squeeze())\n#         X_augmented.append(horizontal_shift(X[i], 0.7))\n#         X_augmented.append(vertical_shift(X[i], 0.7))\n        # X_augmented.append(brightness(X[i], 0.5, 3))\n#         X_augmented.append(zoom(X[i], 0.5))\n        X_augmented.append(channel_shift(X[i], 60))\n        X_augmented.append(horizontal_flip(X[i], True))\n        X_augmented.append(vertical_flip(X[i], True))\n        X_augmented.append(rotation(X[i], 20))\n        X_augmented.append(rotation(X[i], 40))\n        X_augmented.append(rotation(X[i], 60))\n        X_augmented.append(rotation(X[i], -20))\n        X_augmented.append(rotation(X[i], -40))\n        X_augmented.append(rotation(X[i], -60))\n        cpt += 10\n    new_X_augmented = []\n    for i in range(X_augmented.shape[0]):\n        new_X_augmented.append(cv2.resize(X_augmented[i], (INPUT_SIZE, INPUT_SIZE)))\n    new_X_augmented = np.array(new_X_augmented)\n    return np.array(new_X_augmented)\n\ndef add_background_to_data(background_images, hand_images, labels):\n    final_images = []\n    new_labels = []\n    for idx, hand_img in enumerate(tqdm(hand_images)):\n        for background_img in background_images:\n            for r in range(1, 5):\n                resize = int(hand_img.shape[0]*r)\n                hand_img_resized = cv2.resize(hand_img, (resize, resize))[:,:,np.newaxis]\n                y_offset = np.random.randint(background_img.shape[0] - hand_img_resized.shape[0])\n                x_offset = np.random.randint(background_img.shape[1] - hand_img_resized.shape[1])\n                tmp = background_img.copy()\n                tmp[y_offset:y_offset+hand_img_resized.shape[0], x_offset:x_offset+hand_img_resized.shape[1]] = hand_img_resized\n                tmp = cv2.resize(tmp, (INPUT_SIZE, INPUT_SIZE))[:,:,np.newaxis]\n                final_images.append(tmp)\n                new_labels.append(labels[idx])\n    return np.array(final_images), np.array(new_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:12:57.090045Z","iopub.execute_input":"2022-04-04T19:12:57.090407Z","iopub.status.idle":"2022-04-04T19:12:57.317305Z","shell.execute_reply.started":"2022-04-04T19:12:57.090357Z","shell.execute_reply":"2022-04-04T19:12:57.315905Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"X_labelling_augmented, y_labelling_augmented = get_augmented_images(X_labelling, y_labelling)\nprint(X_labelling_augmented.shape)\nprint(y_labelling_augmented.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:12:57.318541Z","iopub.execute_input":"2022-04-04T19:12:57.318823Z","iopub.status.idle":"2022-04-04T19:12:57.415681Z","shell.execute_reply.started":"2022-04-04T19:12:57.318783Z","shell.execute_reply":"2022-04-04T19:12:57.414714Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X, y = add_background_to_data(background_images, X_labelling_augmented, y_labelling_augmented)\nprint(X.shape)\nprint(y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:12:57.418239Z","iopub.execute_input":"2022-04-04T19:12:57.418946Z","iopub.status.idle":"2022-04-04T19:13:33.189975Z","shell.execute_reply.started":"2022-04-04T19:12:57.418882Z","shell.execute_reply":"2022-04-04T19:13:33.188992Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"X_empty = get_augmented_background(background_images, int(X_labelling_augmented.shape[0]/N_LABELS))\ny_empty = np.full((X.shape), N_LABELS)\nprint(X_empty.shape)\nprint(y_empty.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:13:33.191626Z","iopub.execute_input":"2022-04-04T19:13:33.192058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X.shape)\nprint(X_empty.shape)\nnp.concatenate((X, X_empty), axis=0)\nnp.concatenate((Y, Y_empty), axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for _ in range(20):\n    idx = np.random.randint(X.shape[0])\n    plt.imshow(X[idx])\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_names, y = np.unique(y, return_inverse=True) ## Converts to categorical int and get label names\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=VALID_SIZE, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = X_train[::4], X_valid[::4], y_train[::4], y_valid[::4]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape\n\n# LIMIT 16 GB MEMORY ~ (55000, 128, 128, 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building model","metadata":{}},{"cell_type":"code","source":"def build_model():\n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.layers.Conv2D(32, (5, 5), activation='relu', input_shape=(X_train[0].shape))) \n    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n#     model.add(tf.keras.layers.Dropout(rate=0.2))\n    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu')) \n    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n    model.add(tf.keras.layers.Dropout(rate=0.2))\n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.Dense(128, activation='relu'))\n    model.add(tf.keras.layers.Dense(N_LABELS, activation='softmax'))\n    return model\n\ndef get_callbacks():\n    early = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                             min_delta=0,\n                                             patience=15,\n                                             verbose=2,\n                                             mode='auto',\n                                             baseline=None,\n                                             restore_best_weights=True\n                                             )\n#     reduce = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n#                                                   factor=0.1,\n#                                                   patience=15,\n#                                                   verbose=2,\n#                                                   mode='auto',\n#                                                   min_delta=0.0001,\n#                                                   cooldown=0,\n#                                                   min_lr=0\n#                                                  )\n#     return [early, reduce]\n    return [early]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training model","metadata":{}},{"cell_type":"code","source":"if TPU :\n    with strategy.scope():       \n        model = build_model()\n        model.compile(optimizer='adam',\n                      loss='sparse_categorical_crossentropy',\n                      metrics=['accuracy'])\n        model.summary()\nelse :\n    model = build_model()\n    model.compile(optimizer='adam',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n    model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train, \n                    y_train, \n                    epochs=200, \n                    batch_size=BATCH_SIZE, \n                    verbose=2, \n                    validation_data=(X_valid, y_valid), \n                    callbacks=get_callbacks())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('kaggle_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'valid'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'valid'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"X_test = load_test_data(INPUT_SIZE, INPUT_SIZE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(X_test[0])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = np.argmax(model.predict(X_test), axis=1)\nlabel_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(preds)):\n    print(\"=======================================\")\n    plt.imshow(X_test[i])\n    plt.show()\n    print(label_names[preds[i]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inference_ = False\n\nif inference_ :\n    cv2.destroyAllWindows()\n    before = time.time()\n    vid = cv2.VideoCapture(1)\n    while True:\n\n        ret, frame = vid.read()\n        cv2.imshow('frame', frame)\n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\n        img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n        img = cv2.resize(img, (INPUT_SIZE, INPUT_SIZE))\n        img = img.reshape(1, INPUT_SIZE, INPUT_SIZE, 1)\n\n        after = int(time.time() - before)\n        print(label_names[np.argmax(model.predict(img))], end='\\r')\n\n    vid.release()\n    cv2.destroyAllWindows()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}