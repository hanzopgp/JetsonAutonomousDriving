{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f76b207a-be69-4b92-ac8a-e0b5e8d0c3f4",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5474f8b-36df-4041-90ca-b32059d1d7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405da49d-205e-48df-89ac-cef5004ef95b",
   "metadata": {},
   "source": [
    "# Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7195184-6670-4816-a211-b78207173be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = False\n",
    "load_ = True\n",
    "\n",
    "label_name = [\"palm_horizontal\", \"L\", \"fist_horizontal\", \"fist_vertical\", \"thumb_up\", \"index\", \"ok\", \"palm_vertical\", \"C\", \"thumb_down\"]\n",
    "test_size = 0.25\n",
    "img_width = 120\n",
    "img_height = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c646f812-716e-4399-ad8e-a8ee630607bc",
   "metadata": {},
   "source": [
    "# Loading and pre processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e8a04b6-d9f8-4b3a-802b-19f3fad2fe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(width, height, oper_sys):\n",
    "    X = []\n",
    "    y = []\n",
    "    stop = False\n",
    "    if oper_sys == \"windows\":\n",
    "        split_ = \"\\\\\"\n",
    "    else:\n",
    "        split_ = \"/\"\n",
    "    for root, dirs, files in tqdm(os.walk(\".\", topdown=False)): \n",
    "        for name in files:\n",
    "            path = os.path.join(root, name)\n",
    "            if path.endswith(\"png\"):\n",
    "                # Loading labels\n",
    "                category = path.split(split_)[4]\n",
    "                label = int(category.split(\"_\")[0]) - 1\n",
    "                y.append(label)\n",
    "                # Loading images\n",
    "                img = cv2.imread(path)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                img = cv2.resize(img, (width, height))\n",
    "                X.append(img)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X.reshape(X.shape[0], height, width, 1), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df934d42-b7de-416b-8cda-31b90cc6b3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "114it [00:28,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 120, 120, 1)\n",
      "(20000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if load_ : \n",
    "    X, y = load_data(width=img_width, height=img_height, oper_sys=\"windows\")\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    plt.hist(y, bins=10, width=0.7)\n",
    "    plt.title(\"Histogram with 'auto' bins\")\n",
    "    plt.show()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "334005e0-7b2a-45f4-8087-2ee55d1ffabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomment to check if the images are correctly labeled\n",
    "# for i in range(X.shape[0]):\n",
    "#     if i % 500 == 0:\n",
    "#         plt.imshow(X[i])\n",
    "#         plt.show()\n",
    "#         print(label_name[y[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42a85c8-77d4-4b4f-a1a9-4d734fb00bae",
   "metadata": {},
   "source": [
    "# Building and training simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5e77bea-9fcb-4207-b8b4-290c12c26da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(32, (5, 5), activation='relu', input_shape=(img_width, img_height, 1))) \n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu')) \n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(len(label_name), activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b5aa5aa-daf0-4d8d-982f-9d14f77b2601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 116, 116, 32)      832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 58, 58, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 56, 56, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1384576   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,442,122\n",
      "Trainable params: 1,442,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 4.1626e-06 - accuracy: 1.0000\n",
      "Test accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "if train_ :\n",
    "    model = build_model()\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=5, batch_size=64, verbose=2, validation_data=(X_test, y_test))\n",
    "    model.save('tmp_model.h5')\n",
    "else:\n",
    "    model = tf.keras.models.load_model(\"model.h5\", custom_objects=None, compile=True, options=None)\n",
    "\n",
    "model.summary()\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy: {:2.2f}%'.format(test_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b11ae4-9c06-419e-9ff1-fd6074433d40",
   "metadata": {},
   "source": [
    "# Using model in inference with computer webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3e507f5-20ab-4b98-b73e-2ee8226ce45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_ = False\n",
    "\n",
    "if inference_ :\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    before = time.time()\n",
    "    vid = cv2.VideoCapture(1)\n",
    "    while True:\n",
    "        ret, frame = vid.read()\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # after = int(time.time() - before)\n",
    "        # if after % 5 == 0:\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.resize(img, (img_width, img_height))\n",
    "        img = img.reshape(1, img_width, img_height, 1)\n",
    "        print(label_name[np.argmax(model.predict(img))])\n",
    "\n",
    "    vid.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2492587-39d8-44e5-ab31-777df417d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For our problem we should take the best prediction out of 100 images, for each final prediction (less error and less decision taken so the robot doesnt go left right left right etc..)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
