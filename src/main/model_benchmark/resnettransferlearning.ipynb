{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm\nfrom time import time\n\nimport torchvision\nfrom torchvision import models, transforms\n\nimport torch\nfrom torch import nn\nfrom torch.utils.tensorboard import SummaryWriter","metadata":{"execution":{"iopub.status.busy":"2022-02-15T15:53:19.832073Z","iopub.execute_input":"2022-02-15T15:53:19.832936Z","iopub.status.idle":"2022-02-15T15:53:21.767523Z","shell.execute_reply.started":"2022-02-15T15:53:19.83279Z","shell.execute_reply":"2022-02-15T15:53:21.766052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def accuracy(yhat,y):\n    # si y encode les indexes\n    if len(y.shape)==1 or y.size(1)==1:\n        return (torch.argmax(yhat,1).view(y.size(0),-1)== y.view(-1,1)).double().mean()\n    # si y est encodé en onehot\n    return (torch.argmax(yhat,1).view(-1) == torch.argmax(y,1).view(-1)).double().mean()\n\ndef train(model,epochs,train_loader,test_loader,feature_extract=False):\n    model = model.to(device)\n    writer = SummaryWriter(f\"{TB_PATH}/{model.name}\")\n    \n    params_to_update = model.parameters()\n    print(\"params to learn:\")\n    if feature_extract:\n        params_to_update = []\n        for name,param in model.named_parameters():\n            if param.requires_grad == True:\n                params_to_update.append(param)\n                print(\"\\t\",name)\n    else:\n        for name,param in model.named_parameters():\n            if param.requires_grad == True:\n                print(\"\\t\",name)\n    optim = torch.optim.Adam(params_to_update,lr=1e-3)\n    \n    print(f\"running {model.name}\")\n    loss = nn.CrossEntropyLoss()\n    for epoch in tqdm(range(epochs)):\n        cumloss, cumacc, count = 0, 0, 0\n        model.train()\n        for x,y in train_loader:\n            optim.zero_grad()\n            x,y = x.to(device), y.to(device)\n            yhat = model(x)\n            l = loss(yhat,y)\n            l.backward()\n            optim.step()\n            cumloss += l*len(x)\n            cumacc += accuracy(yhat,y)*len(x)\n            count += len(x)\n        writer.add_scalar('loss/train',cumloss/count,epoch)\n        writer.add_scalar('accuracy/train',cumacc/count,epoch)\n        if epoch % 1 == 0:\n            model.eval()\n            with torch.no_grad():\n                cumloss, cumacc, count = 0, 0, 0\n                for x,y in test_loader:\n                    x,y = x.to(device), y.to(device)\n                    yhat = model(x)\n                    cumloss += loss(yhat,y)*len(x)\n                    cumacc += accuracy(yhat,y)*len(x)\n                    count += len(x)\n                writer.add_scalar(f'loss/test',cumloss/count,epoch)\n                writer.add_scalar('accuracy/test',cumacc/count,epoch)\n\ndef set_parameter_requires_grad(model, feature_extract):\n    if feature_extract:\n        for name,p in model.named_parameters():\n            if \"fc\" not in name:\n                p.requires_grad = False    \n            else:\n                p.requires_grad = True  \n                \ndef get_test_data(dataloader, size):\n    X_test, Y_test = next(iter(dataloader))\n    batch_size = len(X_test)\n    n = size//batch_size\n    for i, batch in enumerate(dataloader):\n        if i < n:\n            X_tmp, Y_tmp = batch\n            X_test = torch.cat((X_test, X_tmp), 0)\n            Y_test = torch.cat((Y_test, Y_tmp), 0)\n    return X_test, Y_test","metadata":{"execution":{"iopub.status.busy":"2022-02-15T15:53:21.77021Z","iopub.execute_input":"2022-02-15T15:53:21.771164Z","iopub.status.idle":"2022-02-15T15:53:21.79758Z","shell.execute_reply.started":"2022-02-15T15:53:21.771114Z","shell.execute_reply":"2022-02-15T15:53:21.79647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TB_PATH = \"/tmp/logs/sceance2\"\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nresnet = models.resnet18(pretrained=True)\n\nresnet.fc = nn.Linear(512, 10)\n\nprint(resnet.eval())\n\nset_parameter_requires_grad(resnet, True)","metadata":{"execution":{"iopub.status.busy":"2022-02-15T15:53:21.798976Z","iopub.execute_input":"2022-02-15T15:53:21.799268Z","iopub.status.idle":"2022-02-15T15:53:23.390642Z","shell.execute_reply.started":"2022-02-15T15:53:21.799236Z","shell.execute_reply":"2022-02-15T15:53:23.389369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_size = 224\nbatch_size = 128\n\nmean=[0.485, 0.456, 0.406]\nstd=[0.229, 0.224, 0.225]\n\ntransformresnetTrain=transforms.Compose([ # Cette fois on utilise pas de grayscale car nous avons un gros modele pré-entrainé\n        transforms.RandomResizedCrop(input_size), # selection aléatoire d'une zone de la taille voulue (augmentation des données en apprentissage)\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ])\ntransformresnetTest=transforms.Compose([\n        transforms.Resize(input_size), # selection de la zone centrale de la taille voulue\n        transforms.CenterCrop(input_size),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ])\n\nresnet_trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transformresnetTrain)\nresnet_trainloader = torch.utils.data.DataLoader(resnet_trainset, batch_size=batch_size, pin_memory=True, shuffle=True)\n\nresnet_testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transformresnetTest)\nresnet_testloader = torch.utils.data.DataLoader(resnet_testset, batch_size=batch_size, pin_memory=True, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-15T15:53:23.393063Z","iopub.execute_input":"2022-02-15T15:53:23.393361Z","iopub.status.idle":"2022-02-15T15:53:33.003414Z","shell.execute_reply.started":"2022-02-15T15:53:23.393325Z","shell.execute_reply":"2022-02-15T15:53:33.002235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Entraînement du réseau\nresnet.name = \"resnet\"\ntrain(resnet, 1, resnet_trainloader, resnet_testloader)","metadata":{"execution":{"iopub.status.busy":"2022-02-15T15:53:33.005338Z","iopub.execute_input":"2022-02-15T15:53:33.006271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Accuracy\nX_test, Y_test = get_test_data(resnet_testloader, 1000) \nX_test, Y_test = X_test.to(device), Y_test.to(device)\nprint(\"Acc for resnet transfer learning :\", accuracy(resnet(X_test), Y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for t in (20,40,60,80,100,120):\n    t0 = time()\n    resnet(X_test[:t])\n    print(\"FPS:\", t, \" --> seconds:\", (time() - t0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nPATH = \"./\"\ntorch.save(resnet.state_dict(), os.path.join(PATH,\"resnet.pth\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = \"./\"\nmodel = models.resnet18(pretrained=True)\nmodel.fc = nn.Linear(512, 10)\nmodel.load_state_dict(torch.load(os.path.join(PATH,\"vgg.pth\"),map_location='cpu'))\n\nmodel.eval() \ndummy_input = torch.randn(batch_size, 3, input_size, input_size)  \ntorch.onnx.export(model,   \n                  dummy_input, \n                  \"vgg.onnx\",\n                  export_params=True,\n                  do_constant_folding=True, \n                  input_names = ['modelInput'],\n                  output_names = ['modelOutput'])\nprint(\" \") \nprint('Model has been converted to ONNX') ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}