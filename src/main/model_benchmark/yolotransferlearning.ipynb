{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm\nfrom time import time\n\nimport torchvision\nfrom torchvision import models, transforms\n\nimport torch\nfrom torch import nn\nfrom torch.utils.tensorboard import SummaryWriter","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:49:37.758268Z","iopub.execute_input":"2022-02-16T13:49:37.758744Z","iopub.status.idle":"2022-02-16T13:49:37.765414Z","shell.execute_reply.started":"2022-02-16T13:49:37.758696Z","shell.execute_reply":"2022-02-16T13:49:37.764688Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"def accuracy(yhat,y):\n    # si y encode les indexes\n    if len(y.shape)==1 or y.size(1)==1:\n        return (torch.argmax(yhat,1).view(y.size(0),-1)== y.view(-1,1)).double().mean()\n    # si y est encodé en onehot\n    return (torch.argmax(yhat,1).view(-1) == torch.argmax(y,1).view(-1)).double().mean()\n\ndef train(model,epochs,train_loader,test_loader,feature_extract=False):\n    model = model.to(device)\n    writer = SummaryWriter(f\"{TB_PATH}/{model.name}\")\n    \n    params_to_update = model.parameters()\n    print(\"params to learn:\")\n    if feature_extract:\n        params_to_update = []\n        for name,param in model.named_parameters():\n            if param.requires_grad == True:\n                params_to_update.append(param)\n                print(\"\\t\",name)\n    else:\n        for name,param in model.named_parameters():\n            if param.requires_grad == True:\n                print(\"\\t\",name)\n    optim = torch.optim.Adam(params_to_update,lr=1e-3)\n    \n    print(f\"running {model.name}\")\n    loss = nn.CrossEntropyLoss()\n    for epoch in tqdm(range(epochs)):\n        cumloss, cumacc, count = 0, 0, 0\n        model.train()\n        for x,y in train_loader:\n            optim.zero_grad()\n            x,y = x.to(device), y.to(device)\n            yhat = model(x)\n            l = loss(yhat,y)\n            l.backward()\n            optim.step()\n            cumloss += l*len(x)\n            cumacc += accuracy(yhat,y)*len(x)\n            count += len(x)\n        writer.add_scalar('loss/train',cumloss/count,epoch)\n        writer.add_scalar('accuracy/train',cumacc/count,epoch)\n        if epoch % 1 == 0:\n            model.eval()\n            with torch.no_grad():\n                cumloss, cumacc, count = 0, 0, 0\n                for x,y in test_loader:\n                    x,y = x.to(device), y.to(device)\n                    yhat = model(x)\n                    cumloss += loss(yhat,y)*len(x)\n                    cumacc += accuracy(yhat,y)*len(x)\n                    count += len(x)\n                writer.add_scalar(f'loss/test',cumloss/count,epoch)\n                writer.add_scalar('accuracy/test',cumacc/count,epoch)\n\ndef set_parameter_requires_grad(model, feature_extract):\n    if feature_extract:\n        for name,p in model.named_parameters():\n            p.requires_grad = False    \n\ndef get_test_data(dataloader, size):\n    X_test, Y_test = next(iter(dataloader))\n    batch_size = len(X_test)\n    n = size//batch_size\n    for i, batch in enumerate(dataloader):\n        if i < n:\n            X_tmp, Y_tmp = batch\n            X_test = torch.cat((X_test, X_tmp), 0)\n            Y_test = torch.cat((Y_test, Y_tmp), 0)\n    return X_test, Y_test","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:49:37.767783Z","iopub.execute_input":"2022-02-16T13:49:37.768244Z","iopub.status.idle":"2022-02-16T13:49:37.865417Z","shell.execute_reply.started":"2022-02-16T13:49:37.768208Z","shell.execute_reply":"2022-02-16T13:49:37.863814Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"TB_PATH = \"/tmp/logs/sceance2\"\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# yolov5 = models.yolov518(pretrained=True)\nyolov5 = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n\n# yolov5.fc = nn.Linear(512, 10)\n\nprint(yolov5.eval())\n\nset_parameter_requires_grad(yolov5, True)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:49:37.877404Z","iopub.execute_input":"2022-02-16T13:49:37.877795Z","iopub.status.idle":"2022-02-16T13:49:38.521422Z","shell.execute_reply.started":"2022-02-16T13:49:37.877757Z","shell.execute_reply":"2022-02-16T13:49:38.520674Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"input_size = 224\nbatch_size = 128\n\nmean=[0.485, 0.456, 0.406]\nstd=[0.229, 0.224, 0.225]\n\ntransformyolov5Train=transforms.Compose([ # Cette fois on utilise pas de grayscale car nous avons un gros modele pré-entrainé\n        transforms.RandomResizedCrop(input_size), # selection aléatoire d'une zone de la taille voulue (augmentation des données en apprentissage)\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ])\ntransformyolov5Test=transforms.Compose([\n        transforms.Resize(input_size), # selection de la zone centrale de la taille voulue\n        transforms.CenterCrop(input_size),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ])\n\nyolov5_trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transformyolov5Train)\nyolov5_trainloader = torch.utils.data.DataLoader(yolov5_trainset, batch_size=batch_size, pin_memory=True, shuffle=True)\n\nyolov5_testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transformyolov5Test)\nyolov5_testloader = torch.utils.data.DataLoader(yolov5_testset, batch_size=batch_size, pin_memory=True, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:49:38.524675Z","iopub.execute_input":"2022-02-16T13:49:38.524898Z","iopub.status.idle":"2022-02-16T13:49:40.057351Z","shell.execute_reply.started":"2022-02-16T13:49:38.524870Z","shell.execute_reply":"2022-02-16T13:49:40.056611Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"## Entraînement du réseau\nyolov5.name = \"yolov5\"\n# train(yolov5, 1, yolov5_trainloader, yolov5_testloader)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:49:40.058870Z","iopub.execute_input":"2022-02-16T13:49:40.059168Z","iopub.status.idle":"2022-02-16T13:49:40.063244Z","shell.execute_reply.started":"2022-02-16T13:49:40.059127Z","shell.execute_reply":"2022-02-16T13:49:40.062352Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"## Accuracy\nX_test, Y_test = get_test_data(yolov5_testloader, 1000) \nX_test, Y_test = X_test.to(device), Y_test.to(device)\n# print(\"Acc for yolov5 transfer learning :\", accuracy(yolov5(X_test), Y_test))","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:49:40.064790Z","iopub.execute_input":"2022-02-16T13:49:40.065326Z","iopub.status.idle":"2022-02-16T13:49:56.216803Z","shell.execute_reply.started":"2022-02-16T13:49:40.065256Z","shell.execute_reply":"2022-02-16T13:49:56.216035Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\nimages = yolov5(X_test[:3])\nimages.shape\n# grid_img = torchvision.utils.make_grid(images, nrow=11).cpu()\n# print(grid_img.shape)\n# plt.figure(figsize=(24, 12))\n# plt.imshow(grid_img.permute(1, 2, 0))\n# plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:49:56.218232Z","iopub.execute_input":"2022-02-16T13:49:56.218508Z","iopub.status.idle":"2022-02-16T13:49:56.238224Z","shell.execute_reply.started":"2022-02-16T13:49:56.218470Z","shell.execute_reply":"2022-02-16T13:49:56.237505Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"def classFilter(classdata):\n    classes = []  # create a list\n    for i in range(classdata.shape[0]):         # loop through all predictions\n        classes.append(classdata[i].argmax())   # get the best classification location\n    return classes  # return classes (int)\n\ndef YOLOdetect(output_data):  # input = interpreter, output is boxes(xyxy), classes, scores\n    output_data = output_data[0]                # x(1, 25200, 7) to x(25200, 7)\n    boxes = np.squeeze(output_data[..., :4])    # boxes  [25200, 4]\n    scores = np.squeeze( output_data[..., 4:5]) # confidences  [25200, 1]\n    classes = classFilter(output_data[..., 5:]) # get classes\n    # Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right\n    x, y, w, h = boxes[..., 0], boxes[..., 1], boxes[..., 2], boxes[..., 3] #xywh\n    xyxy = [x - w / 2, y - h / 2, x + w / 2, y + h / 2]  # xywh to xyxy   [4, 25200]\n\n    return xyxy, classes, scores  # output is boxes(x,y,x,y), classes(int), scores(float) [predictions length]","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:49:56.239235Z","iopub.execute_input":"2022-02-16T13:49:56.240806Z","iopub.status.idle":"2022-02-16T13:49:56.249150Z","shell.execute_reply.started":"2022-02-16T13:49:56.240760Z","shell.execute_reply":"2022-02-16T13:49:56.248265Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"\"\"\"Output data\"\"\"\noutput_data = images[0].cpu().detach().numpy()\nxyxy, classes, scores = YOLOdetect(output_data) #boxes(x,y,x,y), classes(int), scores(float) [25200]\n# print(xyxy)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:49:56.252432Z","iopub.execute_input":"2022-02-16T13:49:56.252720Z","iopub.status.idle":"2022-02-16T13:49:56.262401Z","shell.execute_reply.started":"2022-02-16T13:49:56.252687Z","shell.execute_reply":"2022-02-16T13:49:56.261751Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"for t in (20,40,60,80,100,120,400,1000):\n    t0 = time()\n    yolov5(X_test.cpu()[:t])\n    print(\"FPS:\", t, \" --> seconds:\", (time() - t0))","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:49:56.264042Z","iopub.execute_input":"2022-02-16T13:49:56.264682Z","iopub.status.idle":"2022-02-16T13:50:00.656758Z","shell.execute_reply.started":"2022-02-16T13:49:56.264563Z","shell.execute_reply":"2022-02-16T13:50:00.655325Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"import os\nPATH = \"./\"\ntorch.save(yolov5.state_dict(), os.path.join(PATH,\"yolov5s.pth\"))\nmodel=yolov5","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:50:00.658232Z","iopub.execute_input":"2022-02-16T13:50:00.658506Z","iopub.status.idle":"2022-02-16T13:50:01.147641Z","shell.execute_reply.started":"2022-02-16T13:50:00.658451Z","shell.execute_reply":"2022-02-16T13:50:01.146877Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"test_size = 100\ndummy_input = torch.randn(test_size, 3, input_size, input_size)  \ntorch.onnx.export(model,   \n                  dummy_input, \n                  str(PATH+\"yolov5s.onnx\"),\n                  export_params=True,\n                  do_constant_folding=True, \n                  opset_version=11,\n                  input_names = ['modelInput'],\n                  output_names = ['modelOutput'])","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:50:01.149532Z","iopub.execute_input":"2022-02-16T13:50:01.149982Z","iopub.status.idle":"2022-02-16T13:50:04.466769Z","shell.execute_reply.started":"2022-02-16T13:50:01.149931Z","shell.execute_reply":"2022-02-16T13:50:04.465982Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"# !pip install onnx\n# !pip install onnxruntime\n\nimport onnx\nimport onnxruntime\nfrom onnx import numpy_helper\nimport numpy as np\n\nX_test = X_test[:test_size].cpu()\n\nt0 = time()\npred = model(X_test).cpu()\nprint(\"Time for \",test_size,\" images without ONNX inference\", (time() - t0))\nprint(np.array(pred).shape)\n\nsess = onnxruntime.InferenceSession(str(PATH+\"yolov5s.onnx\"))\ninput_name = sess.get_inputs()[0].name\noutput_name = sess.get_outputs()[0].name\nt0 = time()\npred = sess.run([output_name], {input_name: np.array(X_test).astype(np.float32)})[0]\nprint(\"Time for \",test_size,\" images with ONNX inference\", (time() - t0))\nprint(np.array(pred).shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:50:04.470728Z","iopub.execute_input":"2022-02-16T13:50:04.471046Z","iopub.status.idle":"2022-02-16T13:50:07.966155Z","shell.execute_reply.started":"2022-02-16T13:50:04.471005Z","shell.execute_reply":"2022-02-16T13:50:07.965395Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}