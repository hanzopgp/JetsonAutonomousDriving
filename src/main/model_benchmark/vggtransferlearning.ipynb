{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm\nfrom time import time\n\nimport torchvision\nfrom torchvision import models, transforms\n\nimport torch\nfrom torch import nn\nfrom torch.utils.tensorboard import SummaryWriter\n\n# !pip install torchvision onnx-coreml","metadata":{"execution":{"iopub.status.busy":"2022-02-15T15:49:39.834487Z","iopub.execute_input":"2022-02-15T15:49:39.834841Z","iopub.status.idle":"2022-02-15T15:49:41.669248Z","shell.execute_reply.started":"2022-02-15T15:49:39.834753Z","shell.execute_reply":"2022-02-15T15:49:41.668513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def accuracy(yhat,y):\n    # si y encode les indexes\n    if len(y.shape)==1 or y.size(1)==1:\n        return (torch.argmax(yhat,1).view(y.size(0),-1)== y.view(-1,1)).double().mean()\n    # si y est encodé en onehot\n    return (torch.argmax(yhat,1).view(-1) == torch.argmax(y,1).view(-1)).double().mean()\n\ndef train(model,epochs,train_loader,test_loader,feature_extract=False):\n    model = model.to(device)\n    writer = SummaryWriter(f\"{TB_PATH}/{model.name}\")\n    \n    params_to_update = model.parameters()\n    print(\"params to learn:\")\n    if feature_extract:\n        params_to_update = []\n        for name,param in model.named_parameters():\n            if param.requires_grad == True:\n                params_to_update.append(param)\n                print(\"\\t\",name)\n    else:\n        for name,param in model.named_parameters():\n            if param.requires_grad == True:\n                print(\"\\t\",name)\n    optim = torch.optim.Adam(params_to_update,lr=1e-3)\n    \n    print(f\"running {model.name}\")\n    loss = nn.CrossEntropyLoss()\n    for epoch in tqdm(range(epochs)):\n        cumloss, cumacc, count = 0, 0, 0\n        model.train()\n        for x,y in train_loader:\n            optim.zero_grad()\n            x,y = x.to(device), y.to(device)\n            yhat = model(x)\n            l = loss(yhat,y)\n            l.backward()\n            optim.step()\n            cumloss += l*len(x)\n            cumacc += accuracy(yhat,y)*len(x)\n            count += len(x)\n        writer.add_scalar('loss/train',cumloss/count,epoch)\n        writer.add_scalar('accuracy/train',cumacc/count,epoch)\n        if epoch % 1 == 0:\n            model.eval()\n            with torch.no_grad():\n                cumloss, cumacc, count = 0, 0, 0\n                for x,y in test_loader:\n                    x,y = x.to(device), y.to(device)\n                    yhat = model(x)\n                    cumloss += loss(yhat,y)*len(x)\n                    cumacc += accuracy(yhat,y)*len(x)\n                    count += len(x)\n                writer.add_scalar(f'loss/test',cumloss/count,epoch)\n                writer.add_scalar('accuracy/test',cumacc/count,epoch)\n\ndef set_parameter_requires_grad(model, feature_extract):\n    if feature_extract:\n        for name,p in model.named_parameters():\n            if \"features\" in name:\n                p.requires_grad = False    \n            else:\n                p.requires_grad = True  \n                \ndef get_test_data(dataloader, size):\n    X_test, Y_test = next(iter(dataloader))\n    batch_size = len(X_test)\n    n = size//batch_size\n    for i, batch in enumerate(dataloader):\n        if i < n:\n            X_tmp, Y_tmp = batch\n            X_test = torch.cat((X_test, X_tmp), 0)\n            Y_test = torch.cat((Y_test, Y_tmp), 0)\n    return X_test, Y_test","metadata":{"execution":{"iopub.status.busy":"2022-02-15T15:49:41.672244Z","iopub.execute_input":"2022-02-15T15:49:41.672776Z","iopub.status.idle":"2022-02-15T15:49:41.692044Z","shell.execute_reply.started":"2022-02-15T15:49:41.672722Z","shell.execute_reply":"2022-02-15T15:49:41.691139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TB_PATH = \"/tmp/logs/sceance2\"\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nvgg = models.vgg16(pretrained=True)\n\nvgg.classifier[0] = nn.Linear(25088, 8192)\nvgg.classifier[3] = nn.Linear(8192, 1024)\nvgg.classifier[6] = nn.Linear(1024, 10)\nprint(vgg.eval())\n\nset_parameter_requires_grad(vgg, True)","metadata":{"execution":{"iopub.status.busy":"2022-02-15T15:49:41.69497Z","iopub.execute_input":"2022-02-15T15:49:41.695334Z","iopub.status.idle":"2022-02-15T15:49:46.639507Z","shell.execute_reply.started":"2022-02-15T15:49:41.695293Z","shell.execute_reply":"2022-02-15T15:49:46.638679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_size = 224\nbatch_size = 128\n\nmean=[0.485, 0.456, 0.406]\nstd=[0.229, 0.224, 0.225]\n\ntransformVGGTrain=transforms.Compose([ # Cette fois on utilise pas de grayscale car nous avons un gros modele pré-entrainé\n        transforms.RandomResizedCrop(input_size), # selection aléatoire d'une zone de la taille voulue (augmentation des données en apprentissage)\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ])\ntransformVGGTest=transforms.Compose([\n        transforms.Resize(input_size), # selection de la zone centrale de la taille voulue\n        transforms.CenterCrop(input_size),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ])\n\nVGG_trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transformVGGTrain)\nVGG_trainloader = torch.utils.data.DataLoader(VGG_trainset, batch_size=batch_size, pin_memory=True, shuffle=True)\n\nVGG_testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transformVGGTest)\nVGG_testloader = torch.utils.data.DataLoader(VGG_testset, batch_size=batch_size, pin_memory=True, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-15T15:49:46.640684Z","iopub.execute_input":"2022-02-15T15:49:46.641193Z","iopub.status.idle":"2022-02-15T15:49:48.58544Z","shell.execute_reply.started":"2022-02-15T15:49:46.641152Z","shell.execute_reply":"2022-02-15T15:49:48.584667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Entraînement du réseau\nvgg.name = \"VGG\"\ntrain(vgg, 1, VGG_trainloader, VGG_testloader)","metadata":{"execution":{"iopub.status.busy":"2022-02-15T15:49:48.587816Z","iopub.execute_input":"2022-02-15T15:49:48.588081Z","iopub.status.idle":"2022-02-15T15:52:44.731453Z","shell.execute_reply.started":"2022-02-15T15:49:48.588046Z","shell.execute_reply":"2022-02-15T15:52:44.730119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ## Accuracy\n# X_test, Y_test = get_test_data(VGG_testloader, 121) \n# X_test, Y_test = X_test.to(device), Y_test.to(device)\n# print(\"Acc for VGG transfer learning :\", accuracy(vgg(X_test), Y_test))","metadata":{"execution":{"iopub.status.busy":"2022-02-15T15:52:44.733932Z","iopub.execute_input":"2022-02-15T15:52:44.734212Z","iopub.status.idle":"2022-02-15T15:52:44.737832Z","shell.execute_reply.started":"2022-02-15T15:52:44.734176Z","shell.execute_reply":"2022-02-15T15:52:44.737032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_test, Y_test = X_test.to(device), Y_test.to(device)\n# for t in (20,40,60,80,100,120):\n#     t0 = time()\n#     vgg(X_test[:t])\n#     print(\"FPS:\", t, \" --> seconds:\", (time() - t0))","metadata":{"execution":{"iopub.status.busy":"2022-02-15T15:52:44.739328Z","iopub.execute_input":"2022-02-15T15:52:44.739919Z","iopub.status.idle":"2022-02-15T15:52:44.748914Z","shell.execute_reply.started":"2022-02-15T15:52:44.73988Z","shell.execute_reply":"2022-02-15T15:52:44.748135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nPATH = \"./\"\ntorch.save(vgg.state_dict(), os.path.join(PATH,\"vgg.pth\"))","metadata":{"execution":{"iopub.status.busy":"2022-02-15T15:52:44.750423Z","iopub.execute_input":"2022-02-15T15:52:44.751117Z","iopub.status.idle":"2022-02-15T15:52:47.561884Z","shell.execute_reply.started":"2022-02-15T15:52:44.751076Z","shell.execute_reply":"2022-02-15T15:52:47.560828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = \"./\"\nmodel = models.vgg16(pretrained=True)\nmodel.classifier[0] = nn.Linear(25088, 8192)\nmodel.classifier[3] = nn.Linear(8192, 1024)\nmodel.classifier[6] = nn.Linear(1024, 10)\nmodel.load_state_dict(torch.load(os.path.join(PATH,\"vgg.pth\"),map_location='cpu'))\n\nmodel.eval() \ndummy_input = torch.randn(batch_size, 3, input_size, input_size)  \ntorch.onnx.export(model,   \n                  dummy_input, \n                  \"vgg.onnx\",\n                  export_params=True,\n                  do_constant_folding=True, \n                  input_names = ['modelInput'],\n                  output_names = ['modelOutput'])\nprint(\" \") \nprint('Model has been converted to ONNX') ","metadata":{"execution":{"iopub.status.busy":"2022-02-15T15:52:47.576021Z","iopub.execute_input":"2022-02-15T15:52:47.576288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}